<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Speech to Text and Text to Speech with OpenAI</title>
    <!-- Add this in the <head> section -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
    
    <!-- Favicon: inline SVG to avoid 404 requests to /favicon.ico and provide a visible tab icon -->
    <link rel="icon" type="image/svg+xml" href="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 64 64'%3E%3Crect width='64' height='64' rx='12' fill='%23007BFF'/%3E%3Ctext x='50%25' y='54%25' font-size='34' text-anchor='middle' fill='white' font-family='Segoe UI, Roboto, sans-serif'%3EE%3C/text%3E%3C/svg%3E">
    <!-- Legacy shortcut icon for broader compatibility -->
    <link rel="shortcut icon" href="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 64 64'%3E%3Crect width='64' height='64' rx='12' fill='%23007BFF'/%3E%3Ctext x='50%25' y='54%25' font-size='34' text-anchor='middle' fill='white' font-family='Segoe UI, Roboto, sans-serif'%3EE%3C/text%3E%3C/svg%3E">
    <style>
        /* Base Styles */
        body {
            font-family: 'Roboto', sans-serif;
            background-color: #f0f2f5;
            color: #333;
            margin: 0;
            padding: 10px;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            min-height: 10vh;
            box-sizing: border-box;
        }

        h1 {
            font-size: 2rem;
            color: #007BFF;
            margin-bottom: 20px;
        }

        /* Layout */
        .container {
            background: #fff;
            border-radius: 10px;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
            padding: 15px;
            width: 100%;
            max-width: 2048px;
            display: flex;
            flex-direction: row;
            align-items: flex-start;
            box-sizing: border-box;
            gap: 20px;
        }

        .column {
            flex: 1;
            padding: 0 15px;
        }

        .left-column {
            border-right: none;
            display: flex;
            flex-direction: column;
            gap: 15px;
        }

        .right-column {
            display: flex;
            flex-direction: column;
            gap: 15px;
        }

        /* Form Elements */
        label {
            font-weight: 500;
            margin: 0;
            display: block;
            width: 100%;
            text-align: left;
            white-space: nowrap;
        }

        input[type="text"],
        input[type="password"],
        textarea,
        select,
        button {
            width: 98%;
            padding: 10px;
            margin-top: 5px;
            margin-bottom: 15px;
            border: 1px solid #ddd;
            border-radius: 10px;
            font-size: 1rem;
            max-width: none;
        }

        /* Buttons */
        button {
            background-color: #007BFF;
            color: #fff;
            border: none;
            border-radius: 5px;
            cursor: pointer;
            transition: background-color 0.3s;
        }

        button:hover {
            background-color: #0056b3;
        }

        .button-group {
            display: flex;
            gap: 10px;
            margin-top: 10px;
        }

        .button-group button {
            margin: 0;
            padding: 8px 15px;
            height: 36px;
            white-space: nowrap;
        }

        .button-group button i {
            font-size: 1rem;
        }

        /* Status and Helper Text */
        #status {
            font-style: italic;
            color: #666;
            margin: 5px 0;
        }

        .helper-text {
            font-size: 0.8em;
            color: #666;
            display: block;
            margin-top: -10px;
            margin-bottom: 15px;
        }

        /* Live2D Container */
        #live2d-container {
            width: 100%;
            height: 100%;
            position: relative;
            aspect-ratio: 1/1;
            max-width: 600px;
            margin: 0 auto;
            overflow: hidden;
        }

        #live2d-canvas {
            width: 100%;
            height: 100%;
        }

        /* Clipboard Preview */
        #clipboard-preview {
            border: 1px dashed #ccc;
            padding: 10px;
            border-radius: 5px;
            background: #f9f9f9;
        }

        #clipboard-image {
            border-radius: 5px;
        }

        #clipboard-text {
            white-space: pre-wrap;
            margin: 0;
        }

        /* Toggle Switch */
        .toggle-container {
            margin: 15px 0;
            display: flex;
            align-items: center;
            gap: 10px;
        }

        .switch {
            position: relative;
            display: inline-block;
            width: 60px;
            height: 34px;
        }

        .switch input {
            opacity: 0;
            width: 0;
            height: 0;
        }

        .slider {
            position: absolute;
            cursor: pointer;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background-color: #ccc;
            transition: .4s;
        }

        .slider:before {
            position: absolute;
            content: "";
            height: 26px;
            width: 26px;
            left: 4px;
            bottom: 4px;
            background-color: white;
            transition: .4s;
        }

        .slider.round {
            border-radius: 34px;
        }

        .slider.round:before {
            border-radius: 50%;
        }

        input:checked + .slider {
            background-color: #2196F3;
        }

        input:checked + .slider:before {
            transform: translateX(26px);
        }

        /* Collapsible Section */
        .collapsible {
            width: 100%;
            margin-bottom: 15px;
        }

        .collapsible-btn {
            background-color: #f1f1f1;
            color: #444;
            cursor: pointer;
            padding: 18px;
            width: 100%;
            text-align: left;
            border: 1px solid #ddd;
            border-radius: 10px;
            outline: none;
            transition: 0.4s;
        }

        .collapsible-btn.active {
            border-radius: 10px 10px 0 0;
            border-bottom: none;
        }

        .collapsible-btn:hover {
            background-color: #ddd;
        }

        .collapsible-btn:after {
            content: '\002B';
            color: #777;
            font-weight: bold;
            float: right;
            margin-left: 5px;
        }

        .collapsible-btn.active:after {
            content: "\2212";
        }

        .collapsible-content {
            background-color: #f9f9f9;
            padding: 0 15px;
            max-height: 0;
            overflow: hidden;
            transition: max-height 0.3s ease-out;
            border-radius: 0 0 10px 10px;
        }

        .collapsible-content.active {
            max-height: 2000px;
            padding: 15px;
            border: 1px solid #ddd;
            border-top: none;
        }

        /* Responsive Design */
        @media (max-width: 768px) {
            body {
                padding: 5px;
            }

            .container {
                flex-direction: column;
                padding: 10px;
            }

            .column {
                width: 100%;
                padding: 0;
            }

            .left-column {
                margin-bottom: 20px;
            }
        }

        /* Add these styles in the existing <style> section */
        #current-model {
            font-size: 0.8em;
            color: #666;
        }

        #tool-model-dropdown {
            width: 98%;
            padding: 10px;
            margin-top: 5px;
            margin-bottom: 10px;
            border: 1px solid #ddd;
            border-radius: 10px;
            font-size: 1rem;
        }

        #response-output {
            margin-bottom: 15px;
        }

        /* Pulse effect on response window while awaiting API response */
        #response-output.responding {
            border-color: #007BFF;
            animation: responsePulse 1.2s ease-in-out infinite;
            box-shadow: 0 0 0 0 rgba(0, 123, 255, 0.25);
        }

        @keyframes responsePulse {
            0% {
                box-shadow: 0 0 0 0 rgba(0, 123, 255, 0.25);
            }
            50% {
                box-shadow: 0 0 0 6px rgba(0, 123, 255, 0.12);
            }
            100% {
                box-shadow: 0 0 0 0 rgba(0, 123, 255, 0.25);
            }
        }

        #user-input {
            margin-bottom: 10px;
        }

        /* Add or update these CSS styles */
        .input-container {
            display: flex;
            align-items: center;
            gap: 10px;  /* Reduced gap between label and buttons */
            margin-bottom: 5px;
        }

        .button-group {
            display: flex;
            gap: 10px;
        }

        label {
            margin: 0;  /* Remove default margin */
            white-space: nowrap;  /* Prevent label from wrapping */
        }

        /* Update existing button styles */
        button {
            background-color: #007BFF;
            color: #fff;
            border: none;
            border-radius: 5px;
            cursor: pointer;
            font-size: 1rem;
            transition: background-color 0.3s;
        }

        button:hover {
            background-color: #0056b3;
        }

        .button-group button {
            padding: 8px 15px;
            height: 36px;
            white-space: nowrap;
        }

        #status {
            font-style: italic;
            color: #666;
            margin: 5px 0;
        }

        /* Ensure textarea takes full width */
        #user-input {
            width: 98%;
            margin-bottom: 5px;
        }

        /* Update these styles */
        #paste-btn, #start-record-btn, #send-btn {
            padding: 8px 15px;
            min-width: 36px;  /* Make it square */
            width: 36px;      /* Fixed width */
            height: 36px;     /* Fixed height */
            display: flex;
            align-items: center;
            justify-content: center;
        }
    </style>
    <!-- Replace the script section in the head -->
    <script src="https://cubism.live2d.com/sdk-web/cubismcore/live2dcubismcore.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/dylanNew/live2d/webgl/Live2D/lib/live2d.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/pixi.js@6.5.2/dist/browser/pixi.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/eventemitter3@4.0.7/umd/eventemitter3.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/pixi-live2d-display@0.4.0/dist/index.min.js"></script>
    <script src="ai-autogen-call.js"></script>
    <!-- Dependencies for PDF to PowerPoint conversion -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/pdf.js/2.16.105/pdf.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/pptxgenjs@3.12.0/dist/pptxgen.bundle.js"></script>
</head>
<body>
    <div class="container">
        <div class="column left-column">
            <h1><center>Chat to Eva - Enhanced Voice Assistant</center></h1>
            <div id="live2d-container">
                <canvas id="live2d-canvas"></canvas>
            </div>
            
            <!-- Add the collapsible tool settings here -->
            <div class="collapsible">
                <button type="button" class="collapsible-btn">Tool Settings</button>
                <div class="collapsible-content">
                    <!-- Move settings from left column to here -->
                    <label for="api-key">OpenAI API Key:</label>
                    <input type="password" id="api-key" value="X">
                    
                    <label for="endpoint-url">OpenAI API Endpoint:</label>
                    <input type="text" id="endpoint-url" value="http://localhost:1234/v1/chat/completions">

                    <div class="toggle-container">
                        <label for="webcam-toggle">Webcam Mode:</label>
                        <label class="switch">
                            <input type="checkbox" id="webcam-toggle">
                            <span class="slider round"></span>
                        </label>
                    </div>

                    <div class="toggle-container">
                        <label for="clipboard-toggle">Clipboard Vision Mode:</label>
                        <label class="switch">
                            <input type="checkbox" id="clipboard-toggle">
                            <span class="slider round"></span>
                        </label>
                    </div>

                    <div class="toggle-container">
                        <label for="mute-toggle">Mute TTS:</label>
                        <label class="switch">
                            <input type="checkbox" id="mute-toggle">
                            <span class="slider round"></span>
                        </label>
                    </div>

                    <label for="system-prompt">System Prompt:</label>
                    <textarea id="system-prompt" placeholder="You are a friendly AI assistant called EVA."></textarea>
                    
                    <label for="voice-dropdown">Select Voice:</label>
                    <select id="voice-dropdown">
                        <option value="">Loading voices...</option>
                    </select>

                    <div id="webcam-preview-container" style="display: none;">
                        <label>Webcam Preview:</label>
                        <video id="webcam-preview" style="width: 100%; border-radius: 10px;" autoplay playsinline></video>
                    </div>

                    <label for="base-model-dropdown">Base Chat Model:</label>
                    <select id="base-model-dropdown">
                        <option value="">Loading models...</option>
                    </select>
                    <span class="helper-text">Model used for regular chat (default model)</span>

                    <label for="tool-model-dropdown">Tool Processing Model:</label>
                    <select id="tool-model-dropdown">
                        <option value="">Loading models...</option>
                    </select>
                    <span class="helper-text">Model used for processing tool requests (e.g., website navigation)</span>

                    <label for="vision-model-dropdown">Vision Model (Clipboard/Webcam):</label>
                    <select id="vision-model-dropdown">
                        <option value="">Loading models...</option>
                    </select>
                    <span class="helper-text">Model used when webcam mode or clipboard image mode is enabled</span>

                    <label for="live2d-model-dropdown">Live2D Model:</label>
                    <select id="live2d-model-dropdown">
                        <option value="">Loading models...</option>
                    </select>
                    <span class="helper-text">Select which Live2D model to use (shows file name)</span>

                    <label for="live2d-model-list">Live2D Model Paths (one per line):</label>
                    <textarea id="live2d-model-list" rows="4" placeholder="./model_avatar/NAME/FILE.model3.json">./model_avatar/KITU17/KITU17.model3.json
./model_avatar/NVPU-demo/NVPU.model3.json
./model_avatar/RACOON01/RACOON01.model3.json</textarea>
                    <span class="helper-text">Add new model paths on new lines to make them available in the selector</span>

                    <label for="live2d-offset-range">Live2D Vertical Offset (px): <span id="live2d-offset-value">0</span></label>
                    <input type="range" id="live2d-offset-range" min="-400" max="400" step="5" value="0" />
                    <span class="helper-text">Fine-tune the model's vertical position in the view</span>
                </div>
            </div>
        </div>
        
        <div class="column right-column">
            <label for="response-output">Response:</label>
            <textarea id="response-output" rows="30" readonly></textarea>

            <div id="clipboard-preview" style="display: none; margin: 15px 0;">
                <img id="clipboard-image" style="max-width: 100%; display: none;">
                <p id="clipboard-text" style="display: none;"></p>
            </div>

            <label for="user-input">Your Message:</label>
            <textarea id="user-input" rows="4" placeholder="Your text will appear here..."></textarea>
            
            <div class="button-group">
                <button id="paste-btn" title="Paste from Clipboard"><i class="fas fa-clipboard"></i></button>
                <button id="start-record-btn" title="Start Recording"><i class="fas fa-microphone"></i></button>
                <button id="send-btn" title="Send Message"><i class="fas fa-paper-plane"></i></button>
            </div>
            <div id="status"></div>
        </div>
    </div>

    <video id="webcam-video" style="position: absolute; left: -9999px;"></video>

    <script>
        // At the start of your script section, add these lines:
        window.PIXI = PIXI;
        window.EventEmitter3.EventEmitter = EventEmitter3;

        const startRecordBtn = document.getElementById('start-record-btn');
        const sendBtn = document.getElementById('send-btn');
        const userInput = document.getElementById('user-input');
        const responseOutput = document.getElementById('response-output');
        const status = document.getElementById('status');
        const endpointInput = document.getElementById('endpoint-url');
        const apiKeyInput = document.getElementById('api-key');
        const systemPromptInput = document.getElementById('system-prompt');
        const voiceDropdown = document.getElementById('voice-dropdown');
        const SELECTED_VOICE_STORAGE_KEY = 'selectedVoiceURI'; // Persist selected voice for this browser session
        let voices = [];

        // Persist voice selection when the user changes the dropdown
        if (voiceDropdown) {
            voiceDropdown.addEventListener('change', function() {
                const selectedVoiceIndex = parseInt(voiceDropdown.value);
                if (!isNaN(selectedVoiceIndex) && voices[selectedVoiceIndex]) {
                    try {
                        sessionStorage.setItem(SELECTED_VOICE_STORAGE_KEY, voices[selectedVoiceIndex].voiceURI);
                    } catch (persistError) {
                        console.warn('Could not persist selected voice in sessionStorage:', persistError);
                    }
                }
            });
        }
        let audioContext;
        let mediaStreamSource;
        let recorderNode;
        let audioData = [];
        let live2dModel;
        let live2dTickerRegistered = false; // Ensures we only register the Live2D ticker once
        let live2dOffsets = {}; // Persisted map of modelPath -> vertical offset in px
        // Live2D model configuration (selector-driven)
        let modelPath = './model_avatar/RACOON01/RACOON01.model3.json';
        // Add these variables at the top of your script section
        let clipboardData = null;
        let clipboardType = null;
        let webcamStream = null;
        let isProcessing = false;
        let webcamInterval = null;

        // Add these variables at the top of your script section
        let webcamEnabled = false;
        const webcamToggle = document.getElementById('webcam-toggle');
        const currentModelSpan = document.getElementById('current-model');
        // Storage keys for Live2D model list and selection persistence
        const L2D_LIST_KEY = 'live2dModelList';
        const L2D_SELECTED_KEY = 'live2dSelectedModelPath';
        const L2D_OFFSETS_KEY = 'live2dVerticalOffsets'; // Map modelPath -> offset px

        // Add these variables at the top of your script section
        let clipboardVisionEnabled = false;
        const clipboardToggle = document.getElementById('clipboard-toggle');

        // Add these variables near the top of your script section
        let isRecording = false;
        let spacebarPressed = false;

        // Add these variables at the top of your script section
        let availableModels = [];

        // Base chat model selection
        const baseModelDropdown = document.getElementById('base-model-dropdown');
        let baseModel = 'qwen/qwen3-4b';   // Default base model
        let defaultBaseModel = 'qwen/qwen3-4b';

        // Tool processing model selection
        const toolModelDropdown = document.getElementById('tool-model-dropdown');
        let toolModel = 'qwen/qwen3-4b'; // Default tool model
        let defaultToolModel = 'qwen/qwen3-4b'; // Store default model

        // Vision model selection (used for clipboard image mode and webcam mode)
        const visionModelDropdown = document.getElementById('vision-model-dropdown');
        let visionModel = 'qwen/qwen2.5-vl-7b'; // Default vision model
        let defaultVisionModel = 'qwen/qwen2.5-vl-7b';
        // Set the default value for the dropdown
                if (baseModelDropdown) {
            baseModelDropdown.value = defaultBaseModel;
            baseModel = defaultBaseModel;

            // Update base model when user selects a new one
            baseModelDropdown.addEventListener('change', function() {
                baseModel = this.value;
                if (currentModelSpan) {
                    currentModelSpan.textContent = `Current Model: ${getCurrentModel()}`;
                }
            });
        }

        if (toolModelDropdown) {
            toolModelDropdown.value = defaultToolModel;
            toolModel = defaultToolModel;

            // Update tool model when user selects a new one
            toolModelDropdown.addEventListener('change', function() {
                toolModel = this.value;
                if (currentModelSpan) {
                    currentModelSpan.textContent = `Current Model: ${getCurrentModel()}`;
                }
            });
        }

        if (visionModelDropdown) {
            visionModelDropdown.value = defaultVisionModel;
            visionModel = defaultVisionModel;

            // Update vision model when user selects a new one
            visionModelDropdown.addEventListener('change', function() {
                visionModel = this.value;
                if (currentModelSpan) {
                    currentModelSpan.textContent = `Current Model: ${getCurrentModel()}`;
                }
            });
        }

        // Refresh available models when API key or endpoint changes
        apiKeyInput.addEventListener('change', fetchAvailableModels);
        endpointInput.addEventListener('change', fetchAvailableModels);

        // Add this function to fetch available models
        async function fetchAvailableModels() {
            const endpoint = endpointInput.value.replace('/chat/completions', '/models');
            const apiKey = apiKeyInput.value.trim();

            try {
                const response = await fetch(endpoint, {
                    method: 'GET',
                    headers: {
                        'Authorization': `Bearer ${apiKey}`
                    }
                });

                const data = await response.json();
                availableModels = data.data || [];
                
                // Update tool model dropdown
                if (toolModelDropdown) {
                    toolModelDropdown.innerHTML = availableModels
                        .map(model => `<option value="${model.id}" ${model.id === defaultToolModel ? 'selected' : ''}>${model.id}</option>`)
                        .join('');
                    if (!toolModelDropdown.value) {
                        toolModelDropdown.value = defaultToolModel;
                        toolModel = defaultToolModel;
                    }
                }

                // Update base model dropdown
                if (baseModelDropdown) {
                    baseModelDropdown.innerHTML = availableModels
                        .map(model => `<option value="${model.id}" ${model.id === defaultBaseModel ? 'selected' : ''}>${model.id}</option>`)
                        .join('');
                    if (!baseModelDropdown.value) {
                        baseModelDropdown.value = defaultBaseModel;
                        baseModel = defaultBaseModel;
                    }
                }

                // Populate Live2D model list dropdown from persisted storage or textarea
                const live2dList = document.getElementById('live2d-model-list');
                const live2dDropdown = document.getElementById('live2d-model-dropdown');
                const live2dOffsetRange = document.getElementById('live2d-offset-range');
                const live2dOffsetValue = document.getElementById('live2d-offset-value');
                if (live2dList && live2dDropdown) {
                    // Load any persisted list
                    try {
                        const savedList = localStorage.getItem(L2D_LIST_KEY);
                        if (savedList) {
                            live2dList.value = JSON.parse(savedList).join('\n');
                        }
                        const savedSelected = localStorage.getItem(L2D_SELECTED_KEY);
                        if (savedSelected) {
                            modelPath = savedSelected;
                        }
                        const savedOffsets = localStorage.getItem(L2D_OFFSETS_KEY);
                        if (savedOffsets) {
                            live2dOffsets = JSON.parse(savedOffsets);
                        }
                    } catch (e) {
                        console.warn('Unable to read persisted Live2D model list/selection:', e);
                    }

                    const lines = live2dList.value
                        .split(/\r?\n/)
                        .map(l => l.trim())
                        .filter(l => l.length > 0 && l.toLowerCase().endsWith('.model3.json'));

                    // Build dropdown options showing only the file name
                    live2dDropdown.innerHTML = lines
                        .map(path => {
                            const fileName = path.split('/').pop();
                            const selected = path === modelPath ? 'selected' : '';
                            return `<option value="${path}" ${selected}>${fileName}</option>`;
                        })
                        .join('');

                    // If current modelPath is not in list, append it
                    if (lines.indexOf(modelPath) === -1) {
                        const fileName = modelPath.split('/').pop();
                        const opt = document.createElement('option');
                        opt.value = modelPath;
                        opt.textContent = fileName;
                        opt.selected = true;
                        live2dDropdown.appendChild(opt);
                    }

                    // Update modelPath when user selects a new one and persist selection
                    live2dDropdown.onchange = async () => {
                        modelPath = live2dDropdown.value;
                        try { localStorage.setItem(L2D_SELECTED_KEY, modelPath); } catch {}
                        // Set the offset UI to stored value (default 0)
                        const currentOffset = live2dOffsets[modelPath] ?? 0;
                        if (live2dOffsetRange && live2dOffsetValue) {
                            live2dOffsetRange.value = currentOffset;
                            live2dOffsetValue.textContent = String(currentOffset);
                        }
                        // Optionally reinitialize Live2D with the new model
                        try {
                            cleanupLive2D();
                        } catch (e) {
                            console.warn('Error destroying previous Live2D model (safe to ignore):', e);
                        }
                        await initLive2D();
                    };

                    // Rebuild dropdown when the list changes (user adds new lines) and persist list
                    live2dList.addEventListener('input', () => {
                        const updated = live2dList.value
                            .split(/\r?\n/)
                            .map(l => l.trim())
                            .filter(l => l.length > 0 && l.toLowerCase().endsWith('.model3.json'));
                        try { localStorage.setItem(L2D_LIST_KEY, JSON.stringify(updated)); } catch {}

                        // Keep current selection if still present, otherwise select the last added entry
                        const selectedPath = updated.includes(modelPath)
                            ? modelPath
                            : (updated.length > 0 ? updated[updated.length - 1] : '');

                        live2dDropdown.innerHTML = updated
                            .map(path => {
                                const fileName = path.split('/').pop();
                                const selected = path === selectedPath ? 'selected' : '';
                                return `<option value="${path}" ${selected}>${fileName}</option>`;
                            })
                            .join('');

                        if (selectedPath && selectedPath !== modelPath) {
                            modelPath = selectedPath;
                            live2dDropdown.value = modelPath;
                            try { localStorage.setItem(L2D_SELECTED_KEY, modelPath); } catch {}
                            // Update offset UI to new model's stored offset
                            const currentOffset = live2dOffsets[modelPath] ?? 0;
                            if (live2dOffsetRange && live2dOffsetValue) {
                                live2dOffsetRange.value = currentOffset;
                                live2dOffsetValue.textContent = String(currentOffset);
                            }
                            // Reinitialize the model with the new selection
                            try {
                                cleanupLive2D();
                            } catch (e) {
                                console.warn('Error destroying previous Live2D model (safe to ignore):', e);
                            }
                            initLive2D();
                        }
                    });

                    // Offset range change -> update persisted offset and apply immediately
                    if (live2dOffsetRange && live2dOffsetValue) {
                        const applyOffset = (offsetPx) => {
                            if (live2dModel) {
                                // Apply vertical offset to current model
                                live2dModel.y += offsetPx - (live2dOffsets[modelPath] ?? 0);
                            }
                        };
                        // Initialize UI with current offset
                        const initialOffset = live2dOffsets[modelPath] ?? 0;
                        live2dOffsetRange.value = initialOffset;
                        live2dOffsetValue.textContent = String(initialOffset);
                        live2dOffsetRange.addEventListener('input', () => {
                            const newOffset = parseInt(live2dOffsetRange.value, 10) || 0;
                            live2dOffsetValue.textContent = String(newOffset);
                            // Apply delta offset
                            applyOffset(newOffset);
                            // Persist offset map
                            live2dOffsets[modelPath] = newOffset;
                            try { localStorage.setItem(L2D_OFFSETS_KEY, JSON.stringify(live2dOffsets)); } catch {}
                        });
                    }
                }

                // Update vision model dropdown (filter to models that look multimodal if desired)
                if (visionModelDropdown) {
                    visionModelDropdown.innerHTML = availableModels
                        .map(model => `<option value="${model.id}" ${model.id === defaultVisionModel ? 'selected' : ''}>${model.id}</option>`)
                        .join('');
                    if (!visionModelDropdown.value) {
                        visionModelDropdown.value = defaultVisionModel;
                        visionModel = defaultVisionModel;
                    }
                }
            } catch (error) {
                console.error('Error fetching models:', error);
                if (toolModelDropdown) {
                    toolModelDropdown.innerHTML = `<option value="${defaultToolModel}" selected>${defaultToolModel}</option>`;
                    toolModel = defaultToolModel;
                }
                if (baseModelDropdown) {
                    baseModelDropdown.innerHTML = `<option value="${defaultBaseModel}" selected>${defaultBaseModel}</option>`;
                    baseModel = defaultBaseModel;
                }
            }
        }

        // Add this event listener after your other initialization code
        clipboardToggle.addEventListener('change', function() {
            clipboardVisionEnabled = this.checked;
            // Guard against missing span element
            if (currentModelSpan) {
                currentModelSpan.textContent = `Current Model: ${getCurrentModel()}`;
            }
        });

        // Update the webcam toggle event listener
        webcamToggle.addEventListener('change', function() {
            webcamEnabled = this.checked;
            // Guard against missing span element
            if (currentModelSpan) {
                currentModelSpan.textContent = `Current Model: ${getCurrentModel()}`;
            }
            
            // Show/hide webcam preview
            const previewContainer = document.getElementById('webcam-preview-container');
            previewContainer.style.display = webcamEnabled ? 'block' : 'none';
            
            if (webcamEnabled) {
                initWebcam();
                startPeriodicCapture();
            } else {
                if (webcamInterval) {
                    clearInterval(webcamInterval);
                }
                if (webcamStream) {
                    webcamStream.getTracks().forEach(track => track.stop());
                    webcamStream = null;
                }
            }
        });

        // Update the getCurrentModel function to handle tool requests separately
        function getCurrentModel(isToolRequest = false) {
            if (isToolRequest) {
                return toolModelDropdown.value || toolModel;
            }
            // If webcam or clipboard vision is enabled, use the corresponding model
            if (webcamEnabled) {
                return visionModel || 'qwen/qwen2.5-vl-7b';
            }
            if (clipboardVisionEnabled && clipboardType === 'image') {
                return visionModel || 'qwen/qwen2.5-vl-7b';
            }
            if (clipboardVisionEnabled && clipboardType === 'text') {
                return toolModel;
            }
            
            // Reset endpoint URL for other cases if it was changed
            const currentEndpoint = endpointInput.value;
            if (currentEndpoint.includes('api.openai.com')) {
                endpointInput.value = 'http://localhost:1234/v1/chat/completions';
            }
            return baseModel;
        }

        // Populate voice list for Text-to-Speech
        function loadVoices() {
            // Fetch available voices and rebuild the dropdown without losing the user's selection
            voices = speechSynthesis.getVoices();
            voiceDropdown.innerHTML = '';

            let defaultVoiceIndex = 0; // Fallback default

            if (voices.length === 0) {
                console.warn('No voices available yet, waiting for voices to load');
                return;
            }

            // Read any previously selected voice for this session
            let storedVoiceURI = null;
            try {
                storedVoiceURI = sessionStorage.getItem(SELECTED_VOICE_STORAGE_KEY);
            } catch (readError) {
                console.warn('Could not read selected voice from sessionStorage:', readError);
            }

            voices.forEach((voice, index) => {
                const option = document.createElement('option');
                option.value = index;
                option.textContent = `${voice.name} (${voice.lang})`;
                voiceDropdown.appendChild(option);

                // Prefer Microsoft Ana Online; otherwise choose first English voice as a reasonable default
                if (voice.name === 'Microsoft Ana Online (Natural) - English (United States)') {
                    defaultVoiceIndex = index;
                } else if (voice.lang.includes('en-') && defaultVoiceIndex === 0) {
                    defaultVoiceIndex = index;
                }
            });

            // Determine which voice should be selected after re-populating the list
            let selectedIndex = defaultVoiceIndex;
            if (storedVoiceURI) {
                const idx = voices.findIndex(v => v.voiceURI === storedVoiceURI);
                if (idx !== -1) {
                    selectedIndex = idx;
                }
            }

            voiceDropdown.value = String(selectedIndex);

            // Ensure the chosen voice is persisted for the remainder of the session
            try {
                if (!storedVoiceURI && voices[selectedIndex]) {
                    sessionStorage.setItem(SELECTED_VOICE_STORAGE_KEY, voices[selectedIndex].voiceURI);
                }
            } catch (persistError) {
                console.warn('Could not persist default selected voice in sessionStorage:', persistError);
            }

            console.log('Voices loaded:', voices.length, 'Selected voice:', voices[selectedIndex]?.name);
        }

        // Initial load of voices
        loadVoices();
        
        // Handle voice changes
        if (typeof speechSynthesis !== 'undefined') {
            speechSynthesis.onvoiceschanged = function() {
                loadVoices();
            };
        }

        // Function to generate random movement within a range
        function randomInRange(min, max) {
            const result = Math.random() * (max - min) + min;
            console.log(`randomInRange: min=${min}, max=${max}, result=${result}`);
            return result;
        }
	
	// ─── Helper ───
	// Removes everything between <think> … </think> (case-insensitive, multiline)
	function stripThinkTags(text = '') {
    		return text.replace(/<think>[\s\S]*?<\/think>/gi, '').trim();
	}
	
        // Function to create smooth head movement
        async function animateHeadMovement(model, duration) {
            const targetX = randomInRange(-15, 15);
            const targetY = randomInRange(-10, 10);
            const targetZ = randomInRange(-5, 5);
            
            const steps = 60; // Number of animation frames
            const startX = model.internalModel.coreModel.getParameterValueById('ParamAngleX');
            const startY = model.internalModel.coreModel.getParameterValueById('ParamAngleY');
            const startZ = model.internalModel.coreModel.getParameterValueById('ParamAngleZ');
            
            for (let i = 0; i <= steps; i++) {
                const progress = i / steps;
                // Easing function for smooth movement
                const ease = progress * (2 - progress);
                
                const currentX = startX + (targetX - startX) * ease;
                const currentY = startY + (targetY - startY) * ease;
                const currentZ = startZ + (targetZ - startZ) * ease;
                
                model.internalModel.coreModel.setParameterValueById('ParamAngleX', currentX);
                model.internalModel.coreModel.setParameterValueById('ParamAngleY', currentY);
                model.internalModel.coreModel.setParameterValueById('ParamAngleZ', currentZ);
                
                await new Promise(resolve => setTimeout(resolve, duration / steps));
            }
        }

        // Update the textToSpeech function
        function textToSpeech(text) {
            if (!text) {
                console.warn('No text provided for speech');
                return;
            }

            // Check if muted
            if (isMuted) {
                console.log('TTS is muted, skipping speech');
                return;
            }

            // Cancel any ongoing speech
            speechSynthesis.cancel();

            const utterance = new SpeechSynthesisUtterance(text.replace(/\*/g, ''));
            const selectedVoiceIndex = parseInt(voiceDropdown.value);
            
            // Ensure we have voices and a valid selection
            if (voices.length > 0 && !isNaN(selectedVoiceIndex) && voices[selectedVoiceIndex]) {
                utterance.voice = voices[selectedVoiceIndex];
                console.log('Using voice:', voices[selectedVoiceIndex].name);
            } else {
                console.warn('No valid voice selected, using default system voice');
            }

            let isMoving = false;
            const mouthOpenY = "ParamMouthOpenY";
            let headMovementInterval;
            
            utterance.onstart = function() {
                console.log('Speech started');
                if (live2dModel) {
                    headMovementInterval = setInterval(() => {
                        animateHeadMovement(live2dModel, 1000);
                    }, 3000);
                }
            };

            utterance.onboundary = function(event) {
                if (live2dModel) {
                    isMoving = !isMoving;
                    const mouthOpenValue = isMoving ? 1 : 0;
                    live2dModel.internalModel.coreModel.setParameterValueById(mouthOpenY, mouthOpenValue);
                }
            };

            utterance.onend = function() {
                console.log('Speech ended');
                if (headMovementInterval) {
                    clearInterval(headMovementInterval);
                }
                
                if (live2dModel) {
                    live2dModel.internalModel.coreModel.setParameterValueById(mouthOpenY, 0);
                    animateHeadMovement(live2dModel, 1000).then(() => {
                        live2dModel.internalModel.coreModel.setParameterValueById('ParamAngleX', 0);
                        live2dModel.internalModel.coreModel.setParameterValueById('ParamAngleY', 0);
                        live2dModel.internalModel.coreModel.setParameterValueById('ParamAngleZ', 0);
                    });
                }
            };

            utterance.onerror = function(event) {
                console.error('Speech synthesis error:', event);
            };

            utterance.rate = 1.0;
            utterance.pitch = 1.0;

            try {
            speechSynthesis.speak(utterance);
            } catch (error) {
                console.error('Speech synthesis error:', error);
            }
        }

        // Add this helper function to create smoother mouth movements
        function animateMouth() {
            if (!live2dModel) return;
            
            const mouthOpenY = "ParamMouthOpenY";
            const now = Date.now();
            const value = (Math.sin(now * 0.01) + 1) * 0.5; // Creates a smooth 0-1 oscillation
            
            live2dModel.internalModel.coreModel.setParameterValueById(mouthOpenY, value);
            requestAnimationFrame(animateMouth);
        }

        // Replace the document load event listener
        document.addEventListener('DOMContentLoaded', async function() {
            try {
                // Initialize variables from localStorage if available
                try {
                    todoList = JSON.parse(localStorage.getItem('todoList')) || [];
                    memoryCache = JSON.parse(localStorage.getItem('memoryCache')) || [];
                } catch (storageError) {
                    console.warn('Could not access localStorage:', storageError);
                    todoList = [];
                    memoryCache = [];
                }

                // Initialize core features
            loadVoices();
            if (typeof speechSynthesis !== 'undefined' && speechSynthesis.onvoiceschanged !== undefined) {
                speechSynthesis.onvoiceschanged = loadVoices;
            }

            // Fetch available models based on current tool settings
            await fetchAvailableModels();
                await initAudioRecording();
                await initLive2D();
                await initWebcam();

                // Initialize collapsible sections
                const collapsibleBtn = document.querySelector('.collapsible-btn');
                const collapsibleContent = document.querySelector('.collapsible-content');
                
                if (collapsibleBtn && collapsibleContent) {
                    collapsibleBtn.addEventListener('click', function() {
                        this.classList.toggle('active');
                        collapsibleContent.classList.toggle('active');
                        const isExpanded = this.classList.contains('active');
                        this.setAttribute('aria-expanded', isExpanded);
                    });
                }
            } catch (error) {
                console.error('Error during initialization:', error);
            }
        });

        // Initialize audio recording using Web Audio API and AudioWorkletNode
        async function initAudioRecording() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                mediaStreamSource = audioContext.createMediaStreamSource(stream);

                // Load the audio worklet module
                await audioContext.audioWorklet.addModule('recorder-worklet-processor.js');

                recorderNode = new AudioWorkletNode(audioContext, 'recorder-worklet');
                recorderNode.port.onmessage = (event) => {
                    const inputData = event.data;
                    console.log('Received audio data chunk:', inputData.length);
                    audioData.push(new Float32Array(inputData));
                };

                // Initialize the record button state
                startRecordBtn.innerHTML = '<i class="fas fa-microphone"></i>';
                startRecordBtn.title = "Start Recording";
                console.log('Audio recording initialized successfully');
            } catch (error) {
                console.error('Unable to access microphone:', error);
                alert('Unable to access microphone: ' + error.message);
            }
        }

        // Update these two event listeners
        startRecordBtn.addEventListener('click', toggleRecording);

        document.addEventListener('keydown', (e) => {
            if (e.key === ';' && !e.repeat && !isRecording) {
                e.preventDefault(); // Prevent semicolon from being typed
                toggleRecording();
            }
        });

        document.addEventListener('keyup', (e) => {
            if (e.key === ';' && isRecording) {
                e.preventDefault(); // Prevent semicolon from being typed
                toggleRecording();
            }
        });

        // Add this simple toggle function
        function toggleRecording() {
            if (!isRecording) {
                startRecording();
            } else {
                stopRecording();
            }
        }

        // Update the startRecording function
        function startRecording() {
            if (!isRecording && recorderNode && audioContext) {
                // Cancel any ongoing speech
                speechSynthesis.cancel();
                
                // Reset Live2D model expression
                if (live2dModel) {
                    live2dModel.expression(null);
                    // Reset head position
                    live2dModel.internalModel.coreModel.setParameterValueById('ParamAngleX', 0);
                    live2dModel.internalModel.coreModel.setParameterValueById('ParamAngleY', 0);
                    live2dModel.internalModel.coreModel.setParameterValueById('ParamAngleZ', 0);
                    live2dModel.internalModel.coreModel.setParameterValueById('ParamMouthOpenY', 0);
                }

                // Clear previous recordings
                audioData = [];
                
                // Clear the text areas
                userInput.value = '';
                responseOutput.value = '';

                // Connect the nodes and start recording
                mediaStreamSource.connect(recorderNode);
                recorderNode.connect(audioContext.destination); // Add this line
                
                // Update UI
                startRecordBtn.innerHTML = '<i class="fas fa-stop"></i>';
                startRecordBtn.title = "Stop Recording";
                status.textContent = "Recording...";
                isRecording = true;
                console.log("Recording started");
            }
        }

        // Update the stopRecording function
        function stopRecording() {
            if (isRecording && recorderNode && audioContext) {
                // Properly disconnect both ends of the audio nodes
                mediaStreamSource.disconnect();
                recorderNode.disconnect();
                
                // Update UI
                startRecordBtn.innerHTML = '<i class="fas fa-microphone"></i>';
                startRecordBtn.title = "Start Recording";
                status.textContent = "Processing recording...";
                
                // Set recording state to false BEFORE processing the audio
                isRecording = false;
                
                // Process the recorded audio if we have data
                if (audioData.length > 0) {
                    processAudioData();
                } else {
                    status.textContent = "No audio recorded";
                }
            }
        }

        function processAudioData() {
    // Flatten the audio data
    let flatData = flattenArray(audioData);

    // Encode the data into WAV format
    let wavBlob = encodeWAV(flatData, audioContext.sampleRate);

    // Save the WAV file for testing
    // saveWAVFile(wavBlob);

    // Clear audioData for next recording
    audioData = [];

    // Send to Whisper
    sendAudioToWhisper(wavBlob);
}
/*
function saveWAVFile(wavBlob) {
    const url = URL.createObjectURL(wavBlob);
    const a = document.createElement('a');
    a.style.display = 'none';
    a.href = url;
    a.download = 'test_recording.wav';
    document.body.appendChild(a);
    a.click();
    URL.revokeObjectURL(url);
}
*/

        function encodeWAV(samples, sampleRate) {
            const buffer = new ArrayBuffer(44 + samples.length * 2);
            const view = new DataView(buffer);

            /* RIFF identifier */
            writeString(view, 0, 'RIFF');
            /* file length */
            view.setUint32(4, 36 + samples.length * 2, true);
            /* RIFF type */
            writeString(view, 8, 'WAVE');
            /* format chunk identifier */
            writeString(view, 12, 'fmt ');
            /* format chunk length */
            view.setUint32(16, 16, true);
            /* sample format (PCM) */
            view.setUint16(20, 1, true);
            /* channel count */
            view.setUint16(22, 1, true);
            /* sample rate */
            view.setUint32(24, sampleRate, true);
            /* byte rate (sampleRate * blockAlign) */
            view.setUint32(28, sampleRate * 2, true);
            /* block align (channels * bytesPerSample) */
            view.setUint16(32, 2, true);
            /* bits per sample */
            view.setUint16(34, 16, true);
            /* data chunk identifier */
            writeString(view, 36, 'data');
            /* data chunk length */
            view.setUint32(40, samples.length * 2, true);

            // Convert Float32Array samples to 16-bit PCM
            floatTo16BitPCM(view, 44, samples);

            return new Blob([view], { type: 'audio/wav' });
        }

        function writeString(view, offset, string) {
            for (let i = 0; i < string.length; i++) {
                view.setUint8(offset + i, string.charCodeAt(i));
            }
        }

        function floatTo16BitPCM(output, offset, input) {
            for (let i = 0; i < input.length; i++, offset += 2) {
                let s = Math.max(-1, Math.min(1, input[i]));
                output.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7FFF, true);
            }
        }

        function flattenArray(channelData) {
            let length = channelData.reduce((acc, val) => acc + val.length, 0);
            let result = new Float32Array(length);
            let offset = 0;
            for (let data of channelData) {
                result.set(data, offset);
                offset += data.length;
            }
            return result;
        }

        async function sendAudioToWhisper(audioBlob) {
            const apiKey = apiKeyInput.value.trim();
            const whisperEndpoint = 'http://localhost:8001/v1/audio/transcriptions';

            const formData = new FormData();
            formData.append('file', audioBlob, 'recording.wav');
            formData.append('model', 'whisper-1');

            try {
                console.log('Sending audio to Whisper...');
                const response = await fetch(whisperEndpoint, {
                    method: 'POST',
                    headers: {
                        'Authorization': `Bearer ${apiKey}`
                    },
                    body: formData
                });
                const data = await response.json();
                console.log('Whisper response:', data);
                if (data.text) {
                    // Clear the input before adding new text
                    userInput.value = data.text + ' ';
                    status.textContent = "Transcription successful.";
                    // Immediately send the transcribed text to OpenAI
                    fetchOpenAIResponse(userInput.value.trim());
                } else {
                    console.error('Unexpected response format:', data);
                    status.textContent = "Transcription failed. Please try again.";
                }
            } catch (error) {
                console.error('Error with OpenAI Whisper request:', error);
                status.textContent = "Transcription failed. Please try again.";
            }
        }

        // Replace the existing expressionKeywords object with:
        const expressionKeywords = {
            'Love eye': ['happy', 'joy', 'glad', 'excited', 'wonderful', 'love', 'lovely', 'delighted', 'delight', 'romantic'],
            'cry': ['sad', 'upset', 'sorry', 'disappointed', 'unhappy', 'crying', 'cry'],
            'black face': ['surprised', 'surprise', 'shocked', 'shock', 'amazed', 'wow', 'whoa', 'unexpected', 'harsh', 'angry', 'mad', 'upset', 'furious', 'annoyed'],
            'Milk Tea': ['thinking', 'consider', 'perhaps', 'maybe', 'hmm', 'interesting', 'curious', 'thinking', 'think', 'think about', 'thinking about it', 'think about it']
        };

        // Update the detectExpressionFromText function:
        function detectExpressionFromText(text) {
            const lowercaseText = text.toLowerCase();
            console.log('Analyzing text for expressions:', lowercaseText);
            
            for (const [expression, keywords] of Object.entries(expressionKeywords)) {
                console.log(`Checking keywords for ${expression}:`, keywords);
                if (keywords.some(keyword => {
                    const found = lowercaseText.includes(keyword);
                    if (found) console.log(`Found keyword: ${keyword}`);
                    return found;
                })) {
                    console.log(`Expression match found: ${expression}`);
                    // Match the exact expression file names from the model
                    switch(expression) {
                        case 'Love eye':
                            return 'love';  // Use the Name from model3.json
                        case 'cry':
                            return 'cry';   // Use the Name from model3.json
                        case 'black face':
                            return 'black_face';  // Use the Name from model3.json
                        case 'Milk Tea':
                            return 'milk_tea';    // Use the Name from model3.json
                    }
                }
            }
            
            console.log('No expression match found, returning null to reset to default');
            return null;  // Explicitly return null when no expression is found
        }

        // Add this before the tools declaration
        // Storage wrapper
        const storage = {
            data: new Map(),
            isAvailable: false,
            
            init() {
                try {
                    localStorage.setItem('test', 'test');
                    localStorage.removeItem('test');
                    this.isAvailable = true;
                } catch (e) {
                    console.warn('localStorage not available, using in-memory storage');
                    this.isAvailable = false;
                }
            },

            setItem(key, value) {
                if (this.isAvailable) {
                    try {
                        localStorage.setItem(key, value);
                    } catch (e) {
                        console.warn('Error saving to localStorage:', e);
                        this.data.set(key, value);
                    }
                } else {
                    this.data.set(key, value);
                }
            },

            getItem(key) {
                if (this.isAvailable) {
                    try {
                        return localStorage.getItem(key);
                    } catch (e) {
                        console.warn('Error reading from localStorage:', e);
                        return this.data.get(key) || null;
                    }
                }
                return this.data.get(key) || null;
            }
        };

        // Initialize storage
        storage.init();

        // Storage helper functions
        function saveTodoList() {
            storage.setItem('todoList', JSON.stringify(todoList));
        }

        function saveMemory() {
            storage.setItem('memoryCache', JSON.stringify(memoryCache));
        }

        // Initialize variables
        let todoList = [];
        let memoryCache = [];
        let isToolRequest = false;
        let chatHistory = [];  // Single declaration of chatHistory

        try {
            const savedTodoList = storage.getItem('todoList');
            const savedMemoryCache = storage.getItem('memoryCache');
            
            if (savedTodoList) {
                todoList = JSON.parse(savedTodoList);
            }
            if (savedMemoryCache) {
                memoryCache = JSON.parse(savedMemoryCache);
            }
        } catch (error) {
            console.warn('Error loading from storage:', error);
        }

        // Replace the ToolManager with OpenAI-style tool definitions
        const tools = [
                {
                    type: "function",
                    function: {
                        name: "manageTodoList",
                        description: "Manages a persistent todo list with various operations (list, add, update, delete tasks)",
                        parameters: {
                            type: "object",
                            properties: {
                                action: {
                                    type: "string",
                                    enum: ["list", "add", "update", "delete", "clear"],
                                    description: "The action to perform on the todo list"
                                },
                                taskId: {
                                    type: "number",
                                    description: "The ID of the task (required for update and delete actions)"
                                },
                                taskDescription: {
                                    type: "string",
                                    description: "The description of the task (required for add and update actions)"
                                }
                            },
                            required: ["action"]
                        }
                    }
                },
            {
                type: "function",
                function: {
                    name: "uploadToGoogleDrive",
                    description: "Uploads a file to Google Drive using service account authentication",
                    parameters: {
                        type: "object",
                        properties: {
                            filePath: {
                                type: "string",
                                description: "Path to the local file to be uploaded"
                            },
                            fileName: {
                                type: "string",
                                description: "Optional custom name for the file in Drive (defaults to local filename)"
                            }
                        },
                        required: ["filePath"]
                    }
                }
            },
            {
                type: "function",
                function: {
                    name: "scrapeWebsite",
                    description: "Fetches and summarizes content from a website",
                    parameters: {
                        type: "object",
                        properties: {
                            url: {
                                type: "string",
                                description: "The URL of the website to scrape (must include http:// or https://)"
                            }
                        },
                        required: ["url"]
                    }
                }
            },
            {
                type: "function",
                function: {
                    name: "fetchNews",
                    description: "Fetches news articles matching given keywords and saves them to a CSV file",
                    parameters: {
                        type: "object",
                        properties: {
                            searchTerm: {
                                type: "string",
                                description: "Keywords to search the news for (e.g., 'economy', 'climate change')"
                            },
                            filename: {
                                type: "string",
                                description: "CSV filename to save the articles to (e.g., 'news.csv')"
                            }
                        },
                        required: ["searchTerm", "filename"]
                    }
                }
            },
            {
                type: "function",
                function: {
                    name: "pdfToPowerPoint",
                    description: "Converts a PDF into an informative and presentable PowerPoint presentation (.pptx)",
                    parameters: {
                        type: "object",
                        properties: {
                            pdfUrl: {
                                type: "string",
                                description: "Optional: URL of the PDF to convert (http/https). If omitted, set promptUpload to true."
                            },
                            promptUpload: {
                                type: "boolean",
                                description: "If true, prompt the user to upload a local PDF file instead of using a URL"
                            },
                            title: {
                                type: "string",
                                description: "Presentation title to place on the title slide"
                            },
                            author: {
                                type: "string",
                                description: "Optional author name to show on the title slide"
                            },
                            maxSlides: {
                                type: "number",
                                description: "Optional maximum number of content slides to generate (default: 15)"
                            },
                            filename: {
                                type: "string",
                                description: "Output .pptx filename (e.g., 'presentation.pptx')"
                            }
                        },
                        required: ["title", "filename"]
                    }
                }
            },
            {
                type: "function",
                function: {
                    name: "manageMemoryCache",
                    description: "Manages a persistent memory cache with various operations",
                    parameters: {
                        type: "object",
                        properties: {
                            action: {
                                type: "string",
                                enum: ["list", "add", "update", "delete", "clear"],
                                description: "The action to perform on the memory cache"
                            },
                            memId: {
                                type: "number",
                                description: "The ID of the memory cache item"
                            },
                            memDescription: {
                                type: "string",
                                description: "The description of the memory cache item"
                            }
                        },
                        required: ["action"]
                    }
                }
            },
            {
                type: "function",
                function: {
                    name: "navigateToUrl",
                    description: "Opens a URL in a new browser tab",
                    parameters: {
                        type: "object",
                        properties: {
                            url: {
                                type: "string",
                                description: "The URL to navigate to (must include https:// or http://)"
                            }
                        },
                        required: ["url"]
                    }
                }
            },
            {
                type: "function",
                function: {
                    name: "openChatToUser",
                    description: "Opens a Teams chat with specified user",
                    parameters: {
                        type: "object",
                        properties: {
                            url: {
                                type: "string",
                                description: "The Teams URL to open"
                            }
                        },
                        required: ["url"]
                    }
                }
            },
            {
                type: "function",
                function: {
                    name: "calculate",
                    description: "Performs basic mathematical calculations",
                    parameters: {
                        type: "object",
                        properties: {
                            expression: {
                                type: "string",
                                description: "The mathematical expression to evaluate",
                                pattern: "^[0-9+\\-*/\\s.()]+$"
                            }
                        },
                        required: ["expression"]
                    }
                }
            },
            {
                type: "function",
                function: {
                    name: "runWorkflow",
                    description: "Executes a workflow based on the provided prompt",
                    parameters: {
                        type: "object",
                        properties: {
                            contentPrompt: {
                                type: "string",
                                description: "The workflow prompt to execute"
                            }
                        },
                        required: ["contentPrompt"]
                    }
                }
            },
            {
                type: "function",
                function: {
                    name: "webSearch",
                    description: "Searches the web for information about a topic and returns relevant results",
                    parameters: {
                        type: "object",
                        properties: {
                            query: {
                                type: "string",
                                description: "The search query or keywords to look for"
                            }
                        },
                        required: ["query"]
                    }
                }
            },
            {
                type: "function",
                function: {
                    name: "saveToFile",
                    description: "Saves content to a file in the specified directory",
                    parameters: {
                        type: "object",
                        properties: {
                            filename: {
                                type: "string",
                                description: "The name of the file to save (e.g., 'latest_news.txt', 'data.csv')"
                            },
                            content: {
                                type: "string",
                                description: "The content to save to the file"
                            }
                        },
                        required: ["filename", "content"]
                    }
                }
            }
        ];

        // Add the new handler function before executeToolCall
        async function handleSaveToFile({ filename, content }) {
            try {
                // Construct the full path
                const savePath = `C:\\Users\\pc\\scratch\\${filename}`;
                
                // Create a Blob with the content
                const blob = new Blob([content], { type: 'text/plain' });
                
                // Create a download link and trigger it
                const a = document.createElement('a');
                a.href = URL.createObjectURL(blob);
                a.download = filename;
                document.body.appendChild(a);
                a.click();
                document.body.removeChild(a);
                URL.revokeObjectURL(a.href);

                return { 
                    success: true, 
                    message: `Content has been saved to ${filename}` 
                };
            } catch (error) {
                console.error('Save to file error:', error);
                return { 
                    success: false, 
                    message: `Error saving file: ${error.message}` 
                };
            }
        }

        // Update executeToolCall to include the new handler
        async function executeToolCall(toolCall, context) {
            console.log('executeToolCall - Input:', { toolCall, context });
            
            let name, argsString;
            
            // Handle both direct tool call format and function format
            if (toolCall.function) {
                ({ name, arguments: argsString } = toolCall.function);
            } else if (toolCall.name) {
                // Handle direct format
                name = toolCall.name;
                argsString = toolCall.arguments;
            } else {
                console.error('executeToolCall - Invalid toolCall format:', toolCall);
                throw new Error('Invalid tool call format');
            }
            
            if (!name || !argsString) {
                console.error('executeToolCall - Missing required properties:', { name, argsString });
                throw new Error('Invalid tool call format: missing name or arguments');
            }

            console.log('executeToolCall - Extracted values:', { name, argsString });

            try {
                const args = typeof argsString === 'string' ? JSON.parse(argsString) : argsString;
                console.log('executeToolCall - Parsed arguments:', args);

                let result;
                switch (name) {
                    case "manageTodoList":
                        result = await handleTodoList(args);
                        break;
                    case "scrapeWebsite":
                        result = await handleWebScraping(args);
                        break;
                    case "webSearch":
                        result = await handleWebSearch(args);
                        break;
                    case "manageMemoryCache":
                        result = await handleMemoryCache(args);
                        break;
                    case "navigateToUrl":
                        result = await handleNavigation(args);
                        break;
                    case "openChatToUser":
                        result = await handleTeamsChat(args);
                        break;
                    case "calculate":
                        result = await handleCalculation(args, context);
                        break;
                    case "runWorkflow":
                        result = await handleWorkflow(args);
                        break;
                    case "llmQuery":
                        result = await handleLLMQuery(args, context);
                        break;
                    case "saveToFile":
                        result = await handleSaveToFile(args);
                        break;
                    case "fetchNews":
                        result = await handleNews(args);
                        break;
                    // Backward compatibility: route legacy name to the new handler
                    case "fetchRoboticsNews":
                        result = await handleNews(args);
                        break;
                    case "pdfToPowerPoint":
                        result = await handlePdfToPowerPoint(args);
                        break;
                    case "uploadToGoogleDrive":
                        result = await handleGoogleDriveUpload(args);
                        break;
                    default:
                        throw new Error(`Unknown tool: ${name}`);
                }
                console.log('executeToolCall - Result:', result);
                return result;
            } catch (error) {
                console.error('executeToolCall - Error:', error);
                throw error;
            }
        }

        // Individual tool handlers
        async function handleTodoList({ action, taskId, taskDescription }) {
                    try {
                        switch (action) {
                            case "list":
                                if (todoList.length === 0) {
                            return { success: true, message: "Your todo list is empty." };
                        }
                        const taskList = todoList.map((task, index) => `${index + 1}. ${task}`).join('\n');
                        return { success: true, message: "Here are your current tasks:\n" + taskList };

                            case "add":
                                if (!taskDescription) {
                            return { success: false, message: "Task description is required." };
                                }
                                todoList.push(taskDescription);
                        saveTodoList();
                        return { success: true, message: `Added task: ${taskDescription}` };

                            case "update":
                                if (!taskId || !taskDescription) {
                            return { success: false, message: "Both task ID and new description are required." };
                                }
                                if (taskId < 1 || taskId > todoList.length) {
                            return { success: false, message: "Invalid task ID." };
                                }
                                const oldTask = todoList[taskId - 1];
                                todoList[taskId - 1] = taskDescription;
                        saveTodoList();
                        return { success: true, message: `Updated task ${taskId} from "${oldTask}" to "${taskDescription}"` };

                            case "delete":
                                if (!taskId) {
                            return { success: false, message: "Task ID is required." };
                                }
                                if (taskId < 1 || taskId > todoList.length) {
                            return { success: false, message: "Invalid task ID." };
                                }
                                const deletedTask = todoList.splice(taskId - 1, 1)[0];
                        saveTodoList();
                        return { success: true, message: `Deleted task: ${deletedTask}` };

                            case "clear":
                                todoList = [];
                        saveTodoList();
                        return { success: true, message: "Todo list has been cleared." };

                            default:
                        return { success: false, message: "Invalid action." };
                        }
                    } catch (error) {
                        console.error('Todo list operation error:', error);
                return { success: false, message: `Error: ${error.message}` };
            }
        }

        async function handleMemoryCache({ action, memId, memDescription }) {
                    try {
                        switch (action) {
                            case "list":
                                if (memoryCache.length === 0) {
                            return { success: true, message: "Your memory cache is empty." };
                        }
                        const memList = memoryCache.map((mem, index) => `${index + 1}. ${mem}`).join('\n');
                        return { success: true, message: "Here are your memories:\n" + memList };

                            case "add":
                                if (!memDescription) {
                            return { success: false, message: "Memory description is required." };
                                }
                                memoryCache.push(memDescription);
                        saveMemory();
                        return { success: true, message: `Added memory: ${memDescription}` };

                            case "update":
                                if (!memId || !memDescription) {
                            return { success: false, message: "Both memory ID and new description are required." };
                                }
                                if (memId < 1 || memId > memoryCache.length) {
                            return { success: false, message: "Invalid memory ID." };
                                }
                                const oldMem = memoryCache[memId - 1];
                                memoryCache[memId - 1] = memDescription;
                        saveMemory();
                        return { success: true, message: `Updated memory ${memId} from "${oldMem}" to "${memDescription}"` };

                            case "delete":
                                if (!memId) {
                            return { success: false, message: "Memory ID is required." };
                                }
                                if (memId < 1 || memId > memoryCache.length) {
                            return { success: false, message: "Invalid memory ID." };
                                }
                                const deletedMem = memoryCache.splice(memId - 1, 1)[0];
                        saveMemory();
                        return { success: true, message: `Deleted memory: ${deletedMem}` };

                            case "clear":
                                memoryCache = [];
                        saveMemory();
                        return { success: true, message: "Memory cache has been cleared." };

                            default:
                        return { success: false, message: "Invalid action." };
                        }
                    } catch (error) {
                        console.error('Memory cache operation error:', error);
                return { success: false, message: `Error: ${error.message}` };
            }
        }

        async function handleNavigation({ url }) {
            try {
                const urlObj = new URL(url);
                if (confirm(`Would you like to open ${url}?`)) {
                    window.open(url, '_blank');
                    return { success: true, message: "The website has been opened in a new tab." };
                }
                return { success: false, message: "Website opening was cancelled." };
            } catch (error) {
                console.error('Navigation error:', error);
                return { success: false, message: "Invalid URL provided" };
            }
        }

        async function handleTeamsChat({ url }) {
            try {
                if (confirm(`Would you like to open Teams chat?`)) {
                            window.open(url, '_blank');
                    return { success: true, message: "Teams chat has been opened" };
                }
                return { success: false, message: "Teams chat opening was cancelled." };
            } catch (error) {
                console.error('Teams chat error:', error);
                return { success: false, message: "Invalid Teams URL" };
            }
        }

        async function handleCalculation({ expression }, context) {
            try {
                console.log('Handling calculation:', expression);
                console.log('Calculation context:', context);
                
                // Check if expression is empty or undefined
                if (!expression) {
                    console.error('Empty or undefined expression');
                    return { success: false, message: "No mathematical expression provided" };
                }

                // Resolve RESULT placeholder if present
                let resolvedExpression = expression;
                if (expression.includes('RESULT')) {
                    const prevResult = context?.variables?.get('lastCalculation');
                    console.log('Previous calculation result:', prevResult);
                    
                    if (prevResult === undefined || prevResult === null) {
                        console.error('No previous result found for calculation');
                        return { success: false, message: "No previous calculation result available" };
                    }
                    
                    resolvedExpression = expression.replace('RESULT', prevResult.toString());
                    console.log('Resolved expression:', resolvedExpression);
                }

                // Clean the resolved expression
                const cleanExpression = resolvedExpression.toString().replace(/\s+/g, '');
                console.log('Cleaned expression:', cleanExpression);
                
                // Validate the cleaned expression
                if (!cleanExpression || !/^[0-9][0-9+\-*/().]*$/.test(cleanExpression)) {
                    console.error('Invalid expression after cleaning:', cleanExpression);
                    return { success: false, message: "Invalid mathematical expression" };
                }
                
                // Evaluate the expression
                const result = eval(cleanExpression);
                console.log('Calculation result:', result);
                
                if (typeof result !== 'number' || isNaN(result)) {
                    return { success: false, message: "Invalid calculation result" };
                }
                
                // Store the result in the context for future reference
                if (context && context.variables instanceof Map) {
                    context.variables.set('lastCalculation', result);
                    console.log('Stored calculation result in context:', result);
                } else {
                    console.warn('Context not available for storing calculation result');
                }
                
                return { success: true, message: `${cleanExpression} = ${result}` };
            } catch (error) {
                console.error('Calculation error:', error);
                return { success: false, message: `Invalid calculation: ${error.message}` };
            }
        }

        async function handleWorkflow({ contentPrompt }) {
            try {
                const result = await window.runWorkflow(contentPrompt);
                return { success: true, message: result };
            } catch (error) {
                console.error('Workflow error:', error);
                return { success: false, message: `Error: ${error.message}` };
            }
        }

        // Add this new handler function for web scraping
        async function handleWebScraping({ url }) {
            try {
                const urlObj = new URL(url);
                
                // Use the proxy endpoint for fetching the webpage content
                const proxyUrl = `http://localhost:8002/v1/proxy/fetch?url=${encodeURIComponent(url)}`;
                
                // Fetch the webpage content through the proxy
                const response = await fetch(proxyUrl, {
                    method: 'GET',
                    headers: {
                        'Authorization': `Bearer ${apiKeyInput.value}`
                    }
                });

                if (!response.ok) {
                    throw new Error(`Failed to fetch content: ${response.statusText}`);
                }

                const data = await response.json();
                if (!data.content) {
                    throw new Error('No content received from proxy');
                }

                // Create a temporary element to parse the HTML
                const parser = new DOMParser();
                const doc = parser.parseFromString(data.content, 'text/html');
                
                // Remove script and style elements
                doc.querySelectorAll('script, style').forEach(el => el.remove());
                
                // Extract text content
                const textContent = doc.body.textContent.replace(/\s+/g, ' ').trim();
                
                // Use the LLM to summarize the content
                const summaryResponse = await fetch(endpointInput.value, {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                        'Authorization': `Bearer ${apiKeyInput.value}`
                    },
                    body: JSON.stringify({
                        model: getCurrentModel(),
                        messages: [
                            {
                                role: 'system',
                                content: 'You are a helpful assistant that provides clear and concise summaries of web content.'
                            },
                            {
                                role: 'user',
                                content: `Please provide a concise summary of this webpage content:\n\n${textContent.substring(0, 4000)}`
                            }
                        ],
                        max_tokens: 500,
                        temperature: 0.7
                    })
                });

                const summaryData = await summaryResponse.json();
                if (summaryData.choices && summaryData.choices.length > 0) {
                    const summary = summaryData.choices[0].message.content;
                            return { 
                                success: true, 
                        message: `Summary of ${url}:\n\n${summary}` 
                            };
                } else {
                    throw new Error('Failed to generate summary');
                        }
            } catch (error) {
                console.error('Web scraping error:', error);
                        return { 
                            success: false, 
                    message: `Error scraping website: ${error.message}` 
                };
            }
        }

        // Add this new handler function for web searching
        async function handleWebSearch({ query }) {
            try {
                // Use the proxy endpoint for searching
                const proxyUrl = `http://localhost:8002/v1/proxy/search?query=${encodeURIComponent(query)}`;
                
                const response = await fetch(proxyUrl, {
                    method: 'GET',
                    headers: {
                        'Authorization': `Bearer ${apiKeyInput.value}`
                    }
                });

                if (!response.ok) {
                    throw new Error(`Failed to search: ${response.statusText}`);
                }

                const data = await response.json();
                if (!data.results || data.results.length === 0) {
                    const noResultsMessage = `No results found for "${query}".`;
                    // Add to chat history
                    chatHistory.push({
                        role: 'assistant',
                        content: noResultsMessage
                    });
                            return { 
                                success: true, 
                        message: noResultsMessage
                    };
                }

                // Format the results into a readable message
                const resultText = data.results.map((result, index) => 
                    `${index + 1}. ${result.title}\nURL: ${result.url}\n${result.snippet}\n`
                ).join('\n');

                const searchResultMessage = `Search results for "${query}":\n\n${resultText}`;
                
                // Add to chat history
                chatHistory.push({
                    role: 'assistant',
                    content: searchResultMessage
                });

                        return { 
                    success: true, 
                    message: searchResultMessage
                };
            } catch (error) {
                console.error('Web search error:', error);
                const errorMessage = `Error performing web search: ${error.message}`;
                // Add error to chat history
                chatHistory.push({
                    role: 'assistant',
                    content: errorMessage
                });
                        return { 
                            success: false, 
                    message: errorMessage
                };
            }
        }

        // Add this function to parse both XML-style and JSON tool responses
        function parseToolResponse(content) {
            console.log('Parsing tool response:', content);

            // Ignore any <tool> tags that occur inside fenced code blocks
            // This prevents example snippets from being executed as real tool calls
            const contentWithoutCode = typeof content === 'string'
                ? content.replace(/```[\s\S]*?```/g, '')
                : content;

            // Try XML format first, but only if tags appear at top-level content
            const toolMatch = contentWithoutCode.match(/<tool>(.*?)<\/tool>/);
            const paramsMatch = contentWithoutCode.match(/<parameters>([\s\S]*?)<\/parameters>/);
            
            if (toolMatch && paramsMatch) {
                try {
                    const leading = contentWithoutCode.slice(0, toolMatch.index).trim();
                    const trailing = contentWithoutCode.slice(paramsMatch.index + paramsMatch[0].length).trim();

                    // Only treat as a real tool call if tags are top-level (no extra text around)
                    if (leading || trailing) {
                        console.log('Found tool tags but not at top-level; treating as plain text');
                    } else {
                        const toolName = toolMatch[1].trim();
                        const parameters = JSON.parse(paramsMatch[1].trim());
                        console.log('Successfully parsed XML format (top-level):', { toolName, parameters });
                        return {
                            function: {
                                name: toolName,
                                arguments: JSON.stringify(parameters)
                            }
                        };
                    }
                } catch (error) {
                    console.error('Error parsing XML tool response:', error);
                }
            }

            // Try parsing as direct JSON, but only if the content looks like JSON
            if (typeof content === 'string') {
                const trimmed = content.trim();
                if (trimmed.startsWith('{') || trimmed.startsWith('[')) {
                    try {
                        const jsonContent = JSON.parse(trimmed);
                        console.log('Parsed JSON content:', jsonContent);

                        // Handle Qwen-style format with action and contentPrompt
                        if (jsonContent.action && jsonContent.contentPrompt) {
                            console.log('Found Qwen format with action and contentPrompt');
                            return {
                                function: {
                                    name: jsonContent.action,
                                    arguments: JSON.stringify({
                                        contentPrompt: jsonContent.contentPrompt
                                    })
                                }
                            };
                        }

                        // Handle OpenAI-style function calling format
                        if (jsonContent.name && jsonContent.arguments) {
                            console.log('Found OpenAI function calling format');
                            return {
                                function: {
                                    name: jsonContent.name,
                                    arguments: typeof jsonContent.arguments === 'string'
                                        ? jsonContent.arguments
                                        : JSON.stringify(jsonContent.arguments)
                                }
                            };
                        }
                    } catch (error) {
                        // Silently ignore if content is not valid JSON
                        console.debug('Ignoring non-JSON tool response');
                    }
                } else if (trimmed.includes('contentPrompt')) {
                    // Handle case where the entire response is the parameters for a known tool name
                    console.log('Found direct contentPrompt format');
                    return {
                        function: {
                            name: 'runWorkflow',
                            arguments: trimmed
                        }
                    };
                }
            } else if (content && typeof content === 'object') {
                const jsonContent = content;
                // Handle Qwen-style format with action and contentPrompt
                if (jsonContent.action && jsonContent.contentPrompt) {
                    return {
                        function: {
                            name: jsonContent.action,
                            arguments: JSON.stringify({ contentPrompt: jsonContent.contentPrompt })
                        }
                    };
                }
                if (jsonContent.name && jsonContent.arguments) {
                    return {
                        function: {
                            name: jsonContent.name,
                            arguments: typeof jsonContent.arguments === 'string' ? jsonContent.arguments : JSON.stringify(jsonContent.arguments)
                        }
                    };
                }
            }

            console.log('No valid tool response format found');
            return null;
        }

        // Define tool patterns for task extraction
        const TOOL_PATTERNS = {
            runWorkflow: {
                patterns: [
                    /^workflow\.\s*(.+)$/i,
                    /^run workflow[:\s]+(.+)$/i,
                    /^execute workflow[:\s]+(.+)$/i,
                    /^workflow[:\s]+(.+)$/i
                ],
                extractArgs: (match) => ({ contentPrompt: match[1].trim() })
            },
            webSearch: {
                patterns: [
                    /(search|look up|find|get information|information about|tell me about) (.*?)(?=\s*(?:then|,|$))/i,
                    /search (?:for )?["'](.+?)["']/i
                ],
                extractArgs: (match) => ({ query: (match[2] || match[1]).trim() })
            },
            scrapeWebsite: {
                patterns: [
                    /(scrape|read|summarize|get content from|look at) (?:the )?(first|1st|second|2nd|third|3rd|url|website|link|result|content at|page at|site|from) ?(?:from )?(?:the )?(?:url )?(?:at )?(?:address )?(?:["'])?([^"'\s]*)(?:["'])?/i,
                    /(?:go to|visit|open) (?:the )?(?:url|website|link|page) (?:at )?(?:["'])?([^"'\s]*)(?:["'])?/i
                ],
                extractArgs: (match, context) => {
                    const urlArg = match[3] || match[1];
                    // If it's a direct URL, use it; otherwise mark as pending
                    return { url: urlArg?.includes('http') ? urlArg : 'pending' };
                }
            },
            manageTodoList: {
                patterns: [
                    /(add|create|make|new) (?:a )?(?:new )?(?:todo|task|item|reminder|note)(?: (?:to|in|into) (?:the )?(?:todo )?list)?(?: saying| with)? ["']?([^"']+)["']?/i,
                    /(update|change|modify|edit) (?:the )?(?:todo|task|item|reminder|note) (?:number )?(\d+)(?: (?:to|with) ["']?([^"']+)["']?)?/i,
                    /(delete|remove|clear) (?:the )?(?:todo|task|item|reminder|note)(?: number )?(\d+)?/i,
                    /(show|list|display|get) (?:all )?(?:my )?(?:todo|task|item|reminder|note)s?(?:list)?/i
                ],
                extractArgs: (match) => {
                    const action = match[1].toLowerCase();
                    if (action.match(/add|create|make|new/i)) {
                        return { 
                            action: 'add',
                            taskDescription: match[2] || ''
                        };
                    } else if (action.match(/update|change|modify|edit/i)) {
                        return { 
                            action: 'update',
                            taskId: parseInt(match[2]),
                            taskDescription: match[3] || ''
                        };
                    } else if (action.match(/delete|remove/i)) {
                        return {
                            action: 'delete',
                            taskId: parseInt(match[2])
                        };
                    } else if (action === 'clear') {
                        return { action: 'clear' };
                    } else {
                        return { action: 'list' };
                    }
                }
            },
            manageMemoryCache: {
                patterns: [
                    /(?:remember|memorize|note)(?: that| this)? ["']?([^"']+)["']?/i,
                    /(?:update|change|modify|edit)(?: the)? memory (?:item )?(?:number )?(\d+)(?: (?:to|with) ["']?([^"']+)["']?)?/i,
                    /(?:delete|remove|forget|clear)(?: the)? memory(?: item)?(?: number )?(\d+)?/i,
                    /(?:show|list|display|get|recall|what is in|what's in)(?: all)?(?: my)? memory(?:cache)?(?:list)?/i
                ],
                extractArgs: (match) => {
                    const action = match[1]?.toLowerCase();
                    if (action?.match(/remember|memorize|note/i)) {
                        return {
                            action: 'add',
                            memDescription: match[2] || match[1] || ''
                        };
                    } else if (action?.match(/update|change|modify|edit/i)) {
                        return {
                            action: 'update',
                            memId: parseInt(match[2]),
                            memDescription: match[3] || ''
                        };
                    } else if (action?.match(/delete|remove|forget/i)) {
                        return {
                            action: 'delete',
                            memId: parseInt(match[2])
                        };
                    } else if (action === 'clear') {
                        return { action: 'clear' };
                    } else {
                        return { action: 'list' };
                    }
                }
            },
            calculate: {
                patterns: [
                    /(?:calculate|compute|evaluate|solve|what is) (?:the )?(?:expression )?(\d+(?:[+\-*/]\d+)+)/i,
                    /(?:calculate|compute|evaluate|solve|what is) (?:the )?(?:result|answer|previous result|previous answer|last result|last answer) ?([+\-*/]) ?(\d+)/i,
                    /(?:calculate|compute|evaluate|solve|what is) (?:the )?(?:expression )?result ?([+\-*/]) ?(\d+)/i,
                    /(\d+(?:[+\-*/]\d+)+)/i  // Direct calculation pattern
                ],
                extractArgs: (match, context) => {
                    console.log('Calculate match:', match);
                    
                    // Check if this is a calculation using previous result
                    if (match[2] && match[3] || (match[1] && match[2])) {
                        const operator = match[1] || match[2];
                        const value = match[2] || match[3];
                        // Use placeholder for result that will be resolved at execution time
                        const expression = `RESULT${operator}${value}`;
                        console.log('Generated expression with placeholder:', expression);
                        return { expression };
                    }
                    
                    // Direct calculation
                    const expression = match[1] || match[0];
                    console.log('Direct expression:', expression);
                    return { expression: expression.replace(/[^0-9+\-*/\s.()]/g, '').trim() };
                }
            },
            llmQuery: {
                patterns: [
                    /^(?!workflow)(?!run workflow)(?!execute workflow)(what|who|where|when|why|how|tell me|explain|describe|list|give me|show me|can you|please|find|search) .+?(?=\s*(?:then|,|$))/i,
                    /^(?!workflow)(?!run workflow)(?!execute workflow)([^,.]+?(?:is|are|was|were|do|does|did|has|have|had|can|could|will|would|should|may|might)\s+.+?)(?=\s*(?:then|,|$))/i
                ],
                extractArgs: (match) => ({
                    query: match[1] || match[0]
                })
            },
            saveToFile: {
                patterns: [
                    /(?:save|write|store|output|export)(?: the)?(?: result| response| content| data)? to (?:file |filename |filepath )?["']?([^"'\s]+\.(?:txt|csv|json))["']?/i,
                    /(?:create|generate|make)(?: a)? (?:new )?file (?:called |named )?["']?([^"'\s]+\.(?:txt|csv|json))["']? (?:with|containing)(?: the)?(?: result| response| content| data)?/i,
                    /(?:save|write) (?:to|into)(?: a)? file (?:called |named )?["']?([^"'\s]+\.(?:txt|csv|json))["']?/i
                ],
                extractArgs: async (match, context) => {
                    const filename = match[1];
                    // Get the last result from context if available
                    let content = '';
                    if (context && context.previousResults && context.previousResults.length > 0) {
                        const lastResult = context.previousResults[context.previousResults.length - 1];
                        if (lastResult.result.message === "Sure, I'd be happy to help! What do you want to know?") {
                            // Generate content about Pompeii using LLM
                            const response = await fetch(endpointInput.value, {
                                method: 'POST',
                                headers: {
                                    'Content-Type': 'application/json',
                                    'Authorization': `Bearer ${apiKeyInput.value}`
                                },
                                body: JSON.stringify({
                                    model: getCurrentModel(),
                                    messages: [
                                        {
                                            role: 'system',
                                            content: 'You are a knowledgeable historian. Provide a comprehensive but concise overview of the history of Pompeii, including its destruction by Mount Vesuvius and its archaeological significance.'
                                        },
                                        {
                                            role: 'user',
                                            content: 'What happened to Pompeii?'
                                        }
                                    ]
                                })
                            });
                            const data = await response.json();
                            content = data.choices[0].message.content;
                        } else {
                            content = lastResult.result.message || '';
                        }
                    }
                    return {
                        filename: filename,
                        content: content
                    };
                }
            }
        };

        // Update preprocessTask to handle async operations
        async function preprocessTask(task, context) {
            task.originalArguments = task.function.arguments;
            const args = JSON.parse(task.function.arguments);
            
            switch (task.function.name) {
                case 'scrapeWebsite':
                    if (args.url === 'pending' && context.searchResults.length > 0) {
                        const urlLine = context.searchResults.find(line => line.includes('URL:'));
                        if (urlLine) {
                            const url = urlLine.split('URL: ')[1].trim();
                            task.function.arguments = JSON.stringify({ url });
                            responseOutput.value += `→ Found URL to scrape: ${url}\n`;
                        }
                    }
                    break;
                case 'saveToFile':
                    // Re-extract args with async support
                    for (const pattern of TOOL_PATTERNS.saveToFile.patterns) {
                        const match = task.originalText.match(pattern);
                        if (match) {
                            const newArgs = await TOOL_PATTERNS.saveToFile.extractArgs(match, context);
                            task.function.arguments = JSON.stringify(newArgs);
                            break;
                        }
                    }
                    break;
            }
        }

        // Update extractTasks function to handle async operations
        async function extractTasks(prompt) {
            console.log('extractTasks - Starting with prompt:', prompt);
            const tasks = [];
            const segments = prompt.split(/\s*(?:then|next|after that|afterwards|finally)\s*/i);
            console.log('extractTasks - Split segments:', segments);
            
            // Initialize context with variables Map
            const context = {
                variables: new Map(),
                searchResults: [],
                urls: [],
                previousResults: []
            };
            console.log('extractTasks - Initialized context:', context);
            
            for (const segment of segments) {
                let taskFound = false;
                const trimmedSegment = segment.trim();
                console.log('extractTasks - Processing segment:', trimmedSegment);
                
                // Try each tool's patterns
                for (const [toolName, tool] of Object.entries(TOOL_PATTERNS)) {
                    if (taskFound) break;
                    
                    for (const pattern of tool.patterns) {
                        const match = trimmedSegment.match(pattern);
                        if (match) {
                            console.log(`extractTasks - Found match for ${toolName}:`, match);
                            const args = tool.extractArgs.constructor.name === 'AsyncFunction' 
                                ? await tool.extractArgs(match, context)
                                : tool.extractArgs(match, context);
                            console.log('extractTasks - Extracted args:', args);
                            
                            if (args && Object.keys(args).length > 0) {
                                const task = {
                                    function: {
                                        name: toolName,
                                        arguments: JSON.stringify(args)
                                    },
                                    originalText: trimmedSegment,
                                    context: context
                                };
                                console.log('extractTasks - Created task:', task);
                                tasks.push(task);
                                taskFound = true;
                                break;
                            }
                        }
                    }
                }

                // If no tool pattern matched and the segment isn't empty
                if (!taskFound && trimmedSegment) {
                    console.log('extractTasks - No tool match found, treating as LLM query:', trimmedSegment);
                    const task = {
                        function: {
                            name: 'llmQuery',
                            arguments: JSON.stringify({ query: trimmedSegment })
                        },
                        originalText: trimmedSegment,
                        context: context
                    };
                    console.log('extractTasks - Created LLM query task:', task);
                    tasks.push(task);
                }
            }

            console.log('extractTasks - Final tasks:', tasks);
            return tasks;
        }

        // Update the processToolChain function
        async function processToolChain(tasks) {
            console.log('processToolChain - Starting with tasks:', tasks);
            let results = [];
            let context = {
                searchResults: [],
                urls: [],
                variables: new Map(),
                previousResults: []
            };
            console.log('processToolChain - Initialized context:', context);

            // Show initial task detection
            responseOutput.value = `Detected ${tasks.length} tasks in the chain:\n`;
            tasks.forEach((task, index) => {
                console.log(`processToolChain - Task ${index + 1}:`, task);
                responseOutput.value += `${index + 1}. ${task.originalText}\n`;
            });
            responseOutput.value += '\nExecuting tasks...\n\n';

            for (let i = 0; i < tasks.length; i++) {
                const task = tasks[i];
                console.log(`processToolChain - Processing task ${i + 1}/${tasks.length}:`, task);
                
                // Update progress in response box
                responseOutput.value += `Processing task ${i + 1}/${tasks.length}: ${task.originalText}\n`;
                
                try {
                    // Ensure task has access to current context
                    task.context = context;
                    
                    // Pre-process task based on context
                    console.log('processToolChain - Pre-processing task:', task);
                    await preprocessTask(task, context);
                    console.log('processToolChain - After pre-processing:', task);
                    
                    // Execute the task with context
                    console.log('processToolChain - Executing task with context:', context);
                    const result = await executeToolCall(task.function, context);
                    console.log('processToolChain - Task execution result:', result);
                    
                    // Only add successful results
                    if (result && result.success) {
                        // Post-process result and update context
                        console.log('processToolChain - Post-processing result:', result);
                        await postprocessResult(result, task, context);
                        console.log('processToolChain - Updated context:', context);

                        // Store the result
                        context.previousResults.push({
                            task: task.originalText,
                            result: result
                        });

                        results.push({
                            task: task.originalText,
                            result: result
                        });

                        // Show interim result
                        responseOutput.value += `✓ Task completed: ${result.message}\n\n`;
                    } else {
                        console.warn('processToolChain - Task failed:', result);
                        responseOutput.value += `✗ Task failed: ${result?.message || 'Unknown error'}\n\n`;
                    }

                } catch (error) {
                    console.error(`processToolChain - Error in task ${i + 1}:`, error);
                    responseOutput.value += `✗ Task failed: ${error.message}\n\n`;
                }
            }

            // Format final results
            console.log('processToolChain - All results:', results);
            let finalOutput;
            if (results.length > 0) {
                finalOutput = results
                    .map((r, index) => `Step ${index + 1} (${r.task}):\n${r.result.message}`)
                    .join('\n\n---\n\n');
                
                // Only read out the last step using TTS
                const lastResult = results[results.length - 1];
                if (lastResult) {
                    const lastStepOutput = `Final result: ${lastResult.result.message}`;
                    textToSpeech(lastStepOutput);
                }
            } else {
                finalOutput = 'Task chain completed, but no successful results were obtained.';
                textToSpeech(finalOutput);
            }

            // Update response box with final results
            responseOutput.value = finalOutput;
            console.log('processToolChain - Final output:', finalOutput);

            return finalOutput;
        }

        // Helper function to postprocess result and update context
        async function postprocessResult(result, task, context) {
            if (!result.success) return;

            switch (task.function.name) {
                case 'webSearch':
                    if (result.success) {
                        const searchResults = result.message
                            .split('\n\n')[1]
                            .split('\n')
                            .filter(line => line.trim());
                        context.searchResults = searchResults;
                        
                        // Extract URLs for potential future use
                        const urls = searchResults
                            .filter(line => line.includes('URL:'))
                            .map(line => line.split('URL: ')[1].trim());
                        context.urls = urls;
                    }
                    break;
                case 'manageTodoList':
                    // Store the current todo list state in context
                    if (result.success && todoList) {
                        context.currentTodoList = [...todoList];
                    }
                    break;
                case 'manageMemoryCache':
                    // Store the current memory cache state in context
                    if (result.success && memoryCache) {
                        context.currentMemoryCache = [...memoryCache];
                    }
                    break;
                case 'calculate':
                    if (result.success) {
                        const match = result.message.match(/=\s*(-?\d+\.?\d*)/);
                        if (match) {
                            const calculationResult = parseFloat(match[1]);
                            context.variables.set('lastCalculation', calculationResult);
                            console.log('Stored calculation result:', calculationResult);
                        }
                    }
                    break;
                // Add more postprocessing cases for other tools as needed
            }
        }

        // Update the fetchOpenAIResponse function to handle context properly
        async function fetchOpenAIResponse(promptText) {
            let endpoint = endpointInput.value;
            const apiKey = apiKeyInput.value.trim();

            // Initialize context object for both single and chained tool calls
            const context = {
                searchResults: [],
                urls: [],
                variables: new Map(),
                previousResults: []
            };

            // Check for tool chaining before proceeding with normal processing
            const hasChaining = promptText.toLowerCase().includes('then') || 
                               promptText.match(/first.*second|1st.*2nd|step.*step/i);

            if (hasChaining) {
                console.log('Detected task chaining in prompt');
                const tasks = await extractTasks(promptText);
                
                if (tasks.length > 1) {
                    console.log('Executing task chain:', tasks);
                    const chainResult = await processToolChain(tasks);
                    
                    chatHistory.push({
                        role: 'assistant',
                        content: chainResult
                    });
                    
                    responseOutput.value = chainResult;
                    textToSpeech(chainResult);
                    return;
                }
            }
    
            // Determine if we need to use OpenAI's endpoint
            if (clipboardVisionEnabled && clipboardType === 'image') {
                endpoint = 'http://localhost:1234/v1/chat/completions';
            }
                endpointInput.value = endpoint;

            const systemPrompt = `You are EVA, a useful AI assistant that can use various tools to help users.

To use a tool, you MUST ALWAYS respond in this EXACT format:
<tool>tool_name</tool>
<parameters>
{
    "parameter1": "value1",
    "parameter2": "value2"
}
</parameters>

IMPORTANT: Always use the XML-style format shown above. Never return raw JSON or other formats.

Available tools:

1. manageTodoList
Description: Manages a todo list
Parameters:
{
    "action": "list|add|update|delete|clear",
    "taskId": "number (for update/delete)",
    "taskDescription": "string (for add/update)"
}

2. manageMemoryCache
Description: Manages memory storage
Parameters:
{
    "action": "list|add|update|delete|clear",
    "memId": "number (for update/delete)",
    "memDescription": "string (for add/update)"
}

3. navigateToUrl
Description: Opens a website
Parameters:
{
    "url": "string (must include http:// or https://)"
}

4. openChatToUser
Description: Opens Teams chat
Parameters:
{
    "url": "string (Teams URL)"
}

5. calculate
Description: Performs calculations
Parameters:
{
    "expression": "string (e.g., '2 + 2')"
}

6. runWorkflow
Description: Executes workflows for code generation and automation tasks
Parameters:
{
    "contentPrompt": "string (the task to execute)"
}

7. scrapeWebsite
Description: Fetches and summarizes content from a website
Parameters:
{
    "url": "string (must include http:// or https://)"
}

8. webSearch
Description: Searches the web for information about a topic and returns relevant results
Parameters:
{
    "query": "string (the search query or keywords to look for)"
}

9. fetchNews
Description: Fetches news articles matching given keywords and saves them to a CSV file
Parameters:
{
    "searchTerm": "string (keywords to search the news for)",
    "filename": "string (CSV filename to save to)"
}

10. pdfToPowerPoint
Description: Intelligently converts a PDF into a structured PowerPoint presentation using AI. Extracts all text, uses OpenAI to analyze and structure content into intro, key points with details, and conclusion slides.
Parameters:
{
    "pdfUrl": "string (optional URL to the PDF)",
    "promptUpload": "boolean (if true, prompt the user to upload a local PDF)",
    "title": "string (title for the presentation)",
    "author": "string (optional author)",
    "maxSlides": "number (optional maximum number of content slides; default 15)",
    "filename": "string (output .pptx filename)"
}

11. uploadToGoogleDrive
Description: Uploads a file to Google Drive using service account authentication
Parameters:
{
    "filePath": "string (path to the local file to be uploaded)",
    "fileName": "string (optional custom name for the file in Drive)"
}

Examples:
User: "Remember to buy milk"
Assistant: <tool>manageMemoryCache</tool>
<parameters>
{
    "action": "add",
    "memDescription": "Buy milk"
}
</parameters>

User: "Add a task to call John"
Assistant: <tool>manageTodoList</tool>
<parameters>
{
    "action": "add",
    "taskDescription": "Call John"
}
</parameters>

User: "Open google.com"
Assistant: <tool>navigateToUrl</tool>
<parameters>
{
    "url": "https://google.com"
}
</parameters>

User: "Calculate 2 + 2"
Assistant: <tool>calculate</tool>
<parameters>
{
    "expression": "2 + 2"
}
</parameters>

User: "Summarize the content from example.com"
Assistant: <tool>scrapeWebsite</tool>
<parameters>
{
    "url": "https://example.com"
}
</parameters>

User: "Search for information about artificial intelligence"
Assistant: <tool>webSearch</tool>
<parameters>
{
    "query": "artificial intelligence"
}
</parameters>

User: "Get the latest news about climate policy and save it to climate_updates.csv"
Assistant: <tool>fetchNews</tool>
<parameters>
{
    "searchTerm": "climate policy",
    "filename": "climate_updates.csv"
}
</parameters>

User: "Turn this PDF into a PowerPoint: https://example.com/report.pdf. Title it 'Quarterly Report' and save as report.pptx"
Assistant: <tool>pdfToPowerPoint</tool>
<parameters>
{
    "promptUpload": true,
    "title": "Quarterly Report",
    "filename": "report.pptx"
}
</parameters>

User: "Upload the climate_updates.csv file to Google Drive"
Assistant: <tool>uploadToGoogleDrive</tool>
<parameters>
{
    "filePath": "climate_updates.csv",
    "fileName": "Latest Climate News"
}
</parameters>

User: "workflow. code a snake game in python"
Assistant: <tool>runWorkflow</tool>
<parameters>
{
    "contentPrompt": "code a snake game in python"
}
</parameters>

User: "workflow. build a javascript todo app"
Assistant: <tool>runWorkflow</tool>
<parameters>
{
    "contentPrompt": "build a javascript todo application that runs without error in a browser. It should use local storage to save the tasks."
}
</parameters>

User: "workflow. create a react component"
Assistant: <tool>runWorkflow</tool>
<parameters>
{
    "contentPrompt": "create a react component"
}
</parameters>

IMPORTANT REMINDER: Always wrap your tool responses in <tool> and <parameters> tags as shown in the examples above. Never return raw JSON.

Current memory cache contents:
${memoryCache.map((item, index) => `${index + 1}. ${item}`).join('\n')}`;
            
            // Preserve existing system prompt by default; user input overrides it
            const effectiveSystemPrompt = systemPromptInput.value.trim() || systemPrompt;
            const messages = [
                { 
                    role: 'system', 
                    content: effectiveSystemPrompt
                },
                ...(isToolRequest ? [] : chatHistory),
                {
                    role: 'user',
                    content: promptText
                }
            ];

            // Add image content if present
            if (clipboardData && clipboardType === 'image' && clipboardVisionEnabled) {
                const base64Image = await new Promise((resolve) => {
                    const reader = new FileReader();
                    reader.onloadend = () => resolve(reader.result.split(',')[1]);
                    reader.readAsDataURL(clipboardData);
                });
                
                messages.push({
                    role: 'user',
                    content: [
                        {
                            type: 'image_url',
                            image_url: {
                                url: `data:image/jpeg;base64,${base64Image}`,
                                detail: 'auto'
                            }
                        }
                    ]
                });
            }

            const body = {
                model: getCurrentModel(),
                messages: messages,
                max_tokens: 4096,
                temperature: 0.7,
                stream: false,
                // Provide tools per LM Studio tool-use docs
                tools: tools,
                tool_choice: 'auto'
            };

            try {
                // Add pulsing effect to indicate we are waiting for the API
                responseOutput.classList.add('responding');
                console.log('Sending request:', {
                    endpoint,
                    model: getCurrentModel(),
                    prompt: promptText
                });
                console.log('Full request:', JSON.stringify(body, null, 2));
                
                const response = await fetch(endpoint, {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                        'Authorization': `Bearer ${apiKey}`
                    },
                    body: JSON.stringify(body)
                });

                const data = await response.json();
                console.log('Response from LLM:', JSON.stringify(data, null, 2));

                if (data.choices && data.choices.length > 0) {
                    const message = data.choices[0].message;
                    console.log('Processing message:', message);

                    // Handle LM Studio/OpenAI function/tool calling first
                    if (message.tool_calls && Array.isArray(message.tool_calls) && message.tool_calls.length > 0) {
                        try {
                            // Add the assistant's tool call turn to messages
                            messages.push({ role: 'assistant', tool_calls: message.tool_calls });

                            // Execute each tool call and push results
                            for (const tc of message.tool_calls) {
                                const toolResult = await executeToolCall(tc, context);
                                messages.push({
                                    role: 'tool',
                                    content: typeof toolResult === 'string' ? toolResult : JSON.stringify(toolResult),
                                    tool_call_id: tc.id
                                });
                            }

                            // Follow-up request to get the final assistant response after tool execution
                            const followupResponse = await fetch(endpoint, {
                                method: 'POST',
                                headers: {
                                    'Content-Type': 'application/json',
                                    'Authorization': `Bearer ${apiKey}`
                                },
                                body: JSON.stringify({
                                    model: getCurrentModel(),
                                    messages: messages,
                                    max_tokens: 4096,
                                    temperature: 0.7,
                                    tools: tools,
                                    tool_choice: 'auto'
                                })
                            });
                            const followupData = await followupResponse.json();
                            const finalMsg = followupData?.choices?.[0]?.message?.content || '';
                            const finalContent = stripThinkTags(finalMsg);
                            if (finalContent) {
                                chatHistory.push({ role: 'assistant', content: finalContent });
                                responseOutput.value = finalContent;
                                textToSpeech(finalContent);
                                const expressionFile = detectExpressionFromText(finalContent);
                                if (expressionFile && live2dModel) {
                                    await live2dModel.expression(expressionFile);
                                }
                            } else {
                                // Fallback: if the model returned no content after tool calls,
                                // synthesize a simple confirmation from the last tool result
                                const lastToolMsg = messages.slice().reverse().find(m => m.role === 'tool')?.content;
                                let confirmText = '';
                                try {
                                    const parsed = typeof lastToolMsg === 'string' ? JSON.parse(lastToolMsg) : lastToolMsg;
                                    confirmText = parsed?.message || '';
                                } catch (_) {
                                    confirmText = typeof lastToolMsg === 'string' ? lastToolMsg : '';
                                }
                                if (confirmText) {
                                    chatHistory.push({ role: 'assistant', content: confirmText });
                                    responseOutput.value = confirmText;
                                    textToSpeech(confirmText);
                                }
                            }
                            // Remove pulsing effect after receiving the final response
                            responseOutput.classList.remove('responding');
                            return;
                        } catch (toolErr) {
                            console.error('Error handling tool calls via LM Studio/OpenAI format:', toolErr);
                            // Fall back to legacy handling below
                        }
                    }

                    const rawContent = message.content || '';
                    const cleanContent = stripThinkTags(rawContent);
                    if (cleanContent) {
                        // Check for tool calls in Qwen's XML format
                        const toolCall = parseToolResponse(cleanContent);
                        if (toolCall) {
                            console.log('Tool call detected:', toolCall);
                            try {
                                const result = await executeToolCall(toolCall, context);  // Pass the context here
                                console.log('Tool execution result:', result);
                                
                                // Add the assistant's message to chat history
                                chatHistory.push({
                                    role: 'assistant',
                                    content: cleanContent
                                });
                                
                                if (result.success) {
                                    responseOutput.value = result.message;
                                    textToSpeech(result.message);
                                }
                                // Remove pulsing effect after tool execution
                                responseOutput.classList.remove('responding');
                            } catch (error) {
                                console.error('Tool execution error:', error);
                                responseOutput.value = `Error executing tool: ${error.message}`;
                                responseOutput.classList.remove('responding');
                            }
                        } else {
                            // Handle regular message response
                        chatHistory.push({ role: 'assistant', content: cleanContent });
                        responseOutput.value = cleanContent;
                            textToSpeech(cleanContent);
                        
                            // Update Live2D expression
                        const expressionFile = detectExpressionFromText(cleanContent);
                        if (expressionFile && live2dModel) {
                            await live2dModel.expression(expressionFile);
                        }
                        responseOutput.classList.remove('responding');
                    }
                }
                } else {
                    // No choices returned; ensure UI is not left waiting
                    console.warn('LLM returned no choices');
                    const lastToolMsg = messages.slice().reverse().find(m => m.role === 'tool')?.content;
                    if (lastToolMsg) {
                        let fallbackText = '';
                        try {
                            const parsed = typeof lastToolMsg === 'string' ? JSON.parse(lastToolMsg) : lastToolMsg;
                            fallbackText = parsed?.message || '';
                        } catch (_) {
                            fallbackText = typeof lastToolMsg === 'string' ? lastToolMsg : '';
                        }
                        if (fallbackText) {
                            chatHistory.push({ role: 'assistant', content: fallbackText });
                            responseOutput.value = fallbackText;
                            textToSpeech(fallbackText);
                        }
                    }
                }
            } catch (error) {
                console.error('Error:', error);
                responseOutput.value = `Error: ${error.message}. Please try again.`;
            } finally {
                responseOutput.classList.remove('responding');
            }
        }

        sendBtn.addEventListener('click', function () {
            const userText = userInput.value;
            if (userText.trim() === '') {
                alert('Please enter some text or record your voice.');
                return;
            }
            fetchOpenAIResponse(userText);
            userInput.value = '';
        });

        // Update the initLive2D function
        async function initLive2D() {
            try {
                // Wait for the document to be fully loaded
                if (document.readyState !== 'complete') {
                    await new Promise(resolve => window.addEventListener('load', resolve));
                }

                const container = document.getElementById('live2d-container');
                const canvas = document.getElementById('live2d-canvas');
                if (!container || !canvas) {
                    console.warn('Live2D container/canvas not found. Skipping init.');
                    return;
                }
                
                // Ensure the canvas stays in DOM; create PIXI Application with responsive dimensions
                const app = new PIXI.Application({
                    view: canvas,
                    transparent: true,
                    autoStart: true,
                    width: container.clientWidth,
                    height: container.clientHeight
                });

                // Initialize Live2D
                // Register ticker only once to avoid duplicate RAF workloads
                if (!live2dTickerRegistered) {
                    await PIXI.live2d.Live2DModel.registerTicker(PIXI.Ticker);
                    live2dTickerRegistered = true;
                }

                // Load model
                const model = await PIXI.live2d.Live2DModel.from(modelPath, {
                    autoInteract: false,
                    focus: false
                });
                
                // Clear stage and add the fresh model to stage
                app.stage.removeChildren();
                app.stage.addChild(model);

                // Function to resize model
                const resizeModel = () => {
                    app.renderer.resize(container.clientWidth, container.clientHeight);
                    
                    // Increase scale for a closer view
                    const scale = Math.min(
                        container.clientWidth / (model.width * 1.5),  // Changed from 1.2 to 0.8
                        container.clientHeight / (model.height * 1.5)  // Changed from 1.2 to 0.8
                    ) * 2.5;  // Multiply by 1.5 to make it 50% larger
                    
                    model.scale.set(scale);
                    model.x = container.clientWidth / 2;
                    // Base vertical placement (upper body focus), then apply per-model offset (px)
                    const baseY = container.clientHeight / 1.4;
                    const offsetPx = live2dOffsets[modelPath] ?? 0;
                    model.y = baseY + offsetPx;
                };

                // Center the model
                model.anchor.set(0.5, 0.4);
                
                // Initial resize
                resizeModel();

                // Add resize handler (debounced) and store app on model instance for cleanup
                const debouncedResize = (() => {
                    let raf = null;
                    return () => {
                        if (raf) cancelAnimationFrame(raf);
                        raf = requestAnimationFrame(resizeModel);
                    };
                })();
                window.addEventListener('resize', debouncedResize);
                // Store references for proper cleanup when switching models
                model.__app = app;
                model.__resizeHandler = debouncedResize;

                // Rest of your model setup...
                model.draggable = false;
                model.following = false;
                model.interactive = false;
                model.tracking = false;
                model.removeAllListeners();
                
                if (model.internalModel) {
                    model.internalModel.coreModel.setParameterValueById('ParamAngleX', 0);
                    model.internalModel.coreModel.setParameterValueById('ParamAngleY', 0);
                    model.internalModel.coreModel.setParameterValueById('ParamAngleZ', 0);
                    model.internalModel.coreModel.setParameterValueById('ParamEyeBallX', 0);
                    model.internalModel.coreModel.setParameterValueById('ParamEyeBallY', 0);
                }

                live2dModel = model;
                console.log('Live2D model loaded successfully');
                
                // Initialize and test expressions
                await initializeLive2DExpressions(model);

            } catch (error) {
                console.error('Failed to load Live2D model:', error);
            }
        }

        // Helper to safely cleanup existing Live2D resources before switching models
        function cleanupLive2D() {
            try {
                if (!live2dModel) return;
                // Remove resize listener if present
                if (live2dModel.__resizeHandler) {
                    window.removeEventListener('resize', live2dModel.__resizeHandler);
                }
                // Destroy PIXI application if stored
                if (live2dModel.__app) {
                    // Guard against undefined destroy options inside PIXI
                    try {
                        // Do NOT remove the canvas view from the DOM; keep removeView=false
                        live2dModel.__app.destroy(false, { children: true, texture: true, baseTexture: true });
                    } catch {}
                }
                // Destroy Live2D model if possible
                if (typeof live2dModel.destroy === 'function') {
                    try {
                        live2dModel.destroy({ children: true, texture: true, baseTexture: true });
                    } catch {}
                }
            } catch (err) {
                console.warn('cleanupLive2D encountered an issue:', err);
            } finally {
                live2dModel = null;
            }
        }

        // Add this after your existing button event listeners
        document.getElementById('paste-btn').addEventListener('click', async () => {
            try {
                const items = await navigator.clipboard.read();
                const previewContainer = document.getElementById('clipboard-preview');
                const previewImage = document.getElementById('clipboard-image');
                const previewText = document.getElementById('clipboard-text');

                // Reset previous clipboard data
                clipboardData = null;
                clipboardType = null;
                previewImage.style.display = 'none';
                previewText.style.display = 'none';
                
                for (const item of items) {
                    // Handle images
                    if (item.types.includes('image/png') || item.types.includes('image/jpeg')) {
                        const blob = await item.getType(item.types.find(type => type.startsWith('image/')));
                        const imageUrl = URL.createObjectURL(blob);
                        
                        clipboardData = blob;
                        clipboardType = 'image';
                        
                        previewImage.src = imageUrl;
                        previewImage.style.display = 'block';
                        previewContainer.style.display = 'block';
                        break;
                    }
                    // Handle text
                    else if (item.types.includes('text/plain')) {
                        const text = await (await item.getType('text/plain')).text();
                        
                        clipboardData = text;
                        clipboardType = 'text';
                        
                        previewText.textContent = text;
                        previewText.style.display = 'block';
                        previewContainer.style.display = 'block';
                        break;
                    }
                }
            } catch (err) {
                console.error('Failed to read clipboard:', err);
                // Fallback to older clipboard API for text
                try {
                    const text = await navigator.clipboard.readText();
                    clipboardData = text;
                    clipboardType = 'text';
                    
                    const previewText = document.getElementById('clipboard-text');
                    previewText.textContent = text;
                    previewText.style.display = 'block';
                    document.getElementById('clipboard-preview').style.display = 'block';
                } catch (err) {
                    alert('Unable to access clipboard: ' + err.message);
                }
            }
        });

        // Add this new helper function
        function clearClipboardPreview() {
            // Clear the clipboard data variables
            clipboardData = null;
            clipboardType = null;
            
            // Clear the preview elements
            const previewContainer = document.getElementById('clipboard-preview');
            const previewImage = document.getElementById('clipboard-image');
            const previewText = document.getElementById('clipboard-text');
            
            previewContainer.style.display = 'none';
            previewImage.style.display = 'none';
            previewImage.src = '';
            previewText.style.display = 'none';
            previewText.textContent = '';
        }

        // Update the initWebcam function
        async function initWebcam() {
            if (!webcamEnabled) return;
            
            try {
                const video = document.getElementById('webcam-video');
                const preview = document.getElementById('webcam-preview');
                webcamStream = await navigator.mediaDevices.getUserMedia({ 
                    video: {
                        width: { ideal: 640 },
                        height: { ideal: 480 }
                    }
                });
                
                // Set both video elements to use the same stream
                video.srcObject = webcamStream;
                preview.srcObject = webcamStream;
                
                await video.play();
                await preview.play();
                
                console.log('Webcam initialized successfully');
                startPeriodicCapture();
            } catch (error) {
                console.error('Error accessing webcam:', error);
                // If webcam fails to initialize, turn off webcam mode
                webcamToggle.checked = false;
                webcamEnabled = false;
                if (currentModelSpan) {
                    currentModelSpan.textContent = 'Current Model: qwen2.5-coder-3b-instruct';
                }
                document.getElementById('webcam-preview-container').style.display = 'none';
                alert('Failed to initialize webcam. Webcam mode has been disabled.');
            }
        }

        // Function to capture and process webcam image
        async function captureAndProcessWebcam() {
            if (isProcessing || !webcamStream) return;

            const video = document.createElement('video');
            const canvas = document.createElement('canvas');
            const context = canvas.getContext('2d');
            
            try {
                video.srcObject = webcamStream;
                await video.play();

                // Set canvas size to match video dimensions
                canvas.width = video.videoWidth;
                canvas.height = video.videoHeight;
                
                // Draw current video frame to canvas
                context.drawImage(video, 0, 0);
                
                // Convert canvas to blob
                const blob = await new Promise(resolve => canvas.toBlob(resolve, 'image/jpeg'));
                
                // Process the image with the model
                isProcessing = true;
                await processWebcamImage(blob);
                
            } catch (error) {
                console.error('Error capturing webcam image:', error);
            } finally {
                video.srcObject = null;
                isProcessing = false;
            }
        }

        // Function to process webcam image with OpenAI
        async function processWebcamImage(imageBlob) {
            const apiKey = apiKeyInput.value.trim();
            const endpoint = endpointInput.value || 'http://localhost:1234/v1/chat/completions';
            const model = getCurrentModel(); // Dynamically get the current model

            try {
                const base64Image = await new Promise((resolve) => {
                    const reader = new FileReader();
                    reader.onloadend = () => resolve(reader.result.split(',')[1]);
                    reader.readAsDataURL(imageBlob);
                });

                const response = await fetch(endpoint, {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                        'Authorization': `Bearer ${apiKey}`
                    },
                    body: JSON.stringify({
                        model: model,
                        message:
                                {
                                "role": "user",
                                "content": promptText,
                                "images": [`data:image/jpeg;base64,${base64Image}`],
                                "temperature": 0.7,
                                "max_tokens": 4096
                            }
                    })
                });

                const data = await response.json();
                if (data.choices && data.choices.length > 0) {
                    const message = data.choices[0].cleanContent.trim();
                    
                    // Update response output
                    responseOutput.value = message;
                    
                    // Trigger text-to-speech
                    textToSpeech(message);
                    
                    // Extract emotion from message and update expression
                    const emotions = ['happy', 'sad', 'surprised', 'neutral', 'thinking'];
                    const emotion = emotions.find(e => message.toLowerCase().includes(e)) || 'neutral';
                    updateLive2DExpression(emotion);
                    
                    // Add to chat history
                    chatHistory.push({ role: 'assistant', content: message });
                }
            } catch (error) {
                console.error('Error processing webcam image:', error);
                status.textContent = "Failed to process webcam image. Please try again.";
            }
        }

        // Function to update Live2D expression
        function updateLive2DExpression(emotion) {
            if (!live2dModel) return;
            
            let expressionFile = null;
            
            // Map emotions to available expressions
            switch(emotion) {
                case 'happy':
                    expressionFile = 'Love eye.exp3.json';
                    break;
                case 'sad':
                    expressionFile = 'cry.exp3.json';
                    break;
                case 'surprised':
                    expressionFile = 'black face.exp3.json';
                    break;
                case 'thinking':
                    expressionFile = 'Milk Tea.exp3.json';
                    break;
            }
            
            if (expressionFile) {
                live2dModel.expression(expressionFile);
            } else {
                // Reset to default expression
                live2dModel.expression(null);
            }
        }

        // Function to start periodic capture
        function startPeriodicCapture() {
            if (webcamInterval) {
                clearInterval(webcamInterval);
            }
            webcamInterval = setInterval(() => {
                // Only process if not already processing and not speaking
                if (!isProcessing && !speechSynthesis.speaking && chatHistory.length === 0) {
                    captureAndProcessWebcam();
                }
            }, 30000); // 30 seconds
        }

        // Add cleanup function for when the page is closed
        window.addEventListener('beforeunload', () => {
            if (webcamInterval) {
                clearInterval(webcamInterval);
            }
            if (webcamStream) {
                webcamStream.getTracks().forEach(track => track.stop());
            }
        });

        // Add this function to initialize expressions when the model loads
        async function initializeLive2DExpressions(model) {
            try {
                // Log available expressions
                const expressions = await model.expressions;
                console.log('Available expressions:', expressions);
                
                // Test each expression
                if (expressions) {
                    for (const exp of expressions) {
                        console.log(`Testing expression: ${exp}`);
                        try {
                            await model.expression(exp);
                            console.log(`Successfully set expression: ${exp}`);
                        } catch (error) {
                            console.error(`Error setting expression ${exp}:`, error);
                        }
                        await new Promise(resolve => setTimeout(resolve, 1000)); // Wait 1 second between expressions
                    }
                    // Reset to default
                    await model.expression(null);
                }
            } catch (error) {
                console.error('Error initializing expressions:', error);
            }
        }

        // Add this new function to handle direct LLM queries
        async function handleLLMQuery({ query }, context) {
            try {
                const endpoint = endpointInput.value;
                const apiKey = apiKeyInput.value.trim();

                // Format previous results in a clear, structured way
                let enhancedQuery = query;
                if (context.previousResults.length > 0) {
                    const contextString = context.previousResults
                        .map((r, i) => {
                            if (r.task.toLowerCase().includes('calculate')) {
                                const match = r.result.message.match(/=\s*(-?\d+\.?\d*)/);
                                return `Step ${i + 1}: ${r.task} → Result: ${match ? match[1] : r.result.message}`;
                            }
                            return `Step ${i + 1}: ${r.task} → Result: ${r.result.message}`;
                        })
                        .join('\n');

                    enhancedQuery = `Given the following previous steps and their results:\n\n${contextString}\n\nNow, ${query}`;
                    
                    if (query.toLowerCase().includes('that') || query.toLowerCase().includes('it') || query.toLowerCase().includes('the result')) {
                        enhancedQuery += "\n\nPlease use the previous results to provide your answer.";
                    }
                }

                console.log('Enhanced query with context:', enhancedQuery);

                // Build initial messages for this sub-request
                const subMessages = [
                    {
                        role: 'system',
                        content: 'You are a helpful assistant. When responding to queries that reference previous results, use that context to provide accurate answers. If the query references calculations or numeric results, incorporate those numbers in your response.'
                    },
                    {
                        role: 'user',
                        content: enhancedQuery
                    }
                ];

                const response = await fetch(endpoint, {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                        'Authorization': `Bearer ${apiKey}`
                    },
                    body: JSON.stringify({
                        model: getCurrentModel(),
                        messages: subMessages,
                        temperature: 0.7,
                        // Provide tools so the model can decide to call them here as well
                        tools: tools,
                        tool_choice: 'auto'
                    })
                });

                const data = await response.json();
                if (data.choices && data.choices.length > 0) {
                    const msg = data.choices[0].message;
                    // Handle potential tool calls using LM Studio/OpenAI format
                    if (msg.tool_calls && Array.isArray(msg.tool_calls) && msg.tool_calls.length > 0) {
                        try {
                            // Add assistant tool calls
                            subMessages.push({ role: 'assistant', tool_calls: msg.tool_calls });
                            // Execute and add tool results
                            for (const tc of msg.tool_calls) {
                                const toolResult = await executeToolCall(tc, context);
                                subMessages.push({
                                    role: 'tool',
                                    content: typeof toolResult === 'string' ? toolResult : JSON.stringify(toolResult),
                                    tool_call_id: tc.id
                                });
                            }
                            // Finalize with a follow-up call
                            const follow = await fetch(endpoint, {
                                method: 'POST',
                                headers: {
                                    'Content-Type': 'application/json',
                                    'Authorization': `Bearer ${apiKey}`
                                },
                                body: JSON.stringify({
                                    model: getCurrentModel(),
                                    messages: subMessages,
                                    temperature: 0.7,
                                    tools: tools,
                                    tool_choice: 'auto'
                                })
                            });
                            const followJson = await follow.json();
                            const finalText = followJson?.choices?.[0]?.message?.content?.trim() || '';
                            return { success: true, message: finalText };
                        } catch (innerErr) {
                            console.error('Error handling tool calls in handleLLMQuery:', innerErr);
                            // Fall back to plain content if present
                        }
                    }

                    const plain = (msg.content || '').trim();
                    console.log('LLM Response:', plain);
                    return {
                        success: true,
                        message: plain
                    };
                } else {
                    throw new Error('No response from LLM');
                }
            } catch (error) {
                console.error('LLM query error:', error);
                return {
                    success: false,
                    message: `Error getting response: ${error.message}`
                };
            }
        }

        // Add these variables at the top of your script section
        let isMuted = false;
        const muteToggle = document.getElementById('mute-toggle');

        // Add this event listener after your other initialization code
        muteToggle.addEventListener('change', function() {
            isMuted = this.checked;
            if (isMuted) {
                speechSynthesis.cancel(); // Stop any ongoing speech
            }
        });

        async function handleNews({ searchTerm, filename }) {
            const API_KEY = 'ad059d25195f48acab2bfbd089ee8fa1';
            
            try {
                // Fetch news from the API
                const url = `https://newsapi.org/v2/everything?q=${encodeURIComponent(searchTerm)}&apiKey=${API_KEY}`;
                const response = await fetch(url);
                
                if (!response.ok) {
                    throw new Error(`Failed to fetch news: ${response.statusText}`);
                }
                
                const data = await response.json();
                const articles = data.articles || [];
                
                if (articles.length === 0) {
                    return {
                        success: false,
                        message: `No articles found for search term "${searchTerm}"`
                    };
                }
                
                // Create CSV content
                const csvContent = ['Title,URL\n'];
                articles.forEach(article => {
                    const title = article.title.replace(/,/g, ' ');  // Remove commas from titles
                    csvContent.push(`"${title}","${article.url}"\n`);
                });
                
                // Create a Blob with the CSV content
                const blob = new Blob(csvContent, { type: 'text/csv' });
                
                // Create a download link and trigger it
                const a = document.createElement('a');
                a.href = URL.createObjectURL(blob);
                a.download = filename;
                document.body.appendChild(a);
                a.click();
                document.body.removeChild(a);
                URL.revokeObjectURL(a.href);
                
                return {
                    success: true,
                    message: `Successfully saved ${articles.length} news articles to ${filename}`
                };
                
            } catch (error) {
                console.error('News fetch error:', error);
                return {
                    success: false,
                    message: `Error fetching news: ${error.message}`
                };
            }
        }

        // Converts a PDF (by URL or data URL) into an intelligent PowerPoint presentation.
        // Enhanced approach:
        // 1) Load PDF with PDF.js and extract ALL text content
        // 2) Send text to OpenAI LLM for intelligent summarization and structuring
        // 3) Create structured slides based on LLM output (intro, key points, details, conclusion)
        // 4) Save the enhanced PPTX file
        async function handlePdfToPowerPoint({ pdfUrl, promptUpload = false, title, author = "", maxSlides = 15, filename }) {
            try {
                if (!window.pdfjsLib) {
                    throw new Error('PDF.js not loaded');
                }
                if (!window.PptxGenJS) {
                    throw new Error('PptxGenJS not loaded');
                }

                // Configure PDF.js worker if available
                if (window.pdfjsLib.GlobalWorkerOptions) {
                    window.pdfjsLib.GlobalWorkerOptions.workerSrc = 'https://cdnjs.cloudflare.com/ajax/libs/pdf.js/2.16.105/pdf.worker.min.js';
                }

                // If requested, prompt the user to upload a PDF
                if (!pdfUrl && promptUpload) {
                    const file = await promptForLocalPdf();
                    if (!file) {
                        return { success: false, message: 'No PDF selected.' };
                    }
                    // Use data URL for local files to avoid CORS issues
                    pdfUrl = await readFileAsDataUrl(file);
                }
                if (!pdfUrl) {
                    throw new Error('No PDF source provided. Provide pdfUrl or set promptUpload=true.');
                }

                const loadingTask = window.pdfjsLib.getDocument({ url: pdfUrl, withCredentials: false });
                const pdf = await loadingTask.promise;

                // Extract ALL text content from the PDF
                let fullText = '';
                for (let pageIndex = 1; pageIndex <= pdf.numPages; pageIndex++) {
                    const page = await pdf.getPage(pageIndex);
                    const textContent = await page.getTextContent();
                    const pageText = textContent.items.map(it => it.str).join(' ').replace(/\s+/g, ' ').trim();
                    fullText += pageText + ' ';
                }

                // Clean up the extracted text
                fullText = fullText.trim().replace(/\s+/g, ' ');
                
                if (!fullText || fullText.length < 50) {
                    throw new Error('Could not extract sufficient text content from PDF');
                }

                // Use OpenAI to intelligently structure the content
                const structuredContent = await generateStructuredPresentation(fullText, title, maxSlides);
                
                if (!structuredContent) {
                    throw new Error('Failed to generate structured content from PDF text');
                }

                // Create PowerPoint with structured content
                const pptx = new window.PptxGenJS();
                pptx.layout = 'LAYOUT_16x9';

                // Title slide
                {
                    const slide = pptx.addSlide();
                    slide.addText(title, { x: 0.5, y: 1.2, w: 9, h: 1, fontSize: 36, bold: true });
                    if (author) {
                        slide.addText(author, { x: 0.5, y: 2.1, w: 9, h: 0.6, fontSize: 18, color: '666666' });
                    }
                    // Add a subtitle if available
                    if (structuredContent.subtitle) {
                        slide.addText(structuredContent.subtitle, { 
                            x: 0.5, y: 2.8, w: 9, h: 0.5, fontSize: 16, color: '888888', italic: true 
                        });
                    }
                }

                // Introduction slide
                if (structuredContent.introduction) {
                    const slide = pptx.addSlide();
                    slide.addText('Introduction', { x: 0.5, y: 0.5, w: 9, h: 0.6, fontSize: 28, bold: true, color: '2B5AA0' });
                    slide.addText(structuredContent.introduction, {
                        x: 0.5,
                        y: 1.3,
                        w: 9,
                        h: 4.0,
                        fontSize: 16,
                        lineSpacing: 28
                    });
                }

                // Key points slides
                if (structuredContent.keyPoints && structuredContent.keyPoints.length > 0) {
                    for (let i = 0; i < structuredContent.keyPoints.length; i++) {
                        const keyPoint = structuredContent.keyPoints[i];
                        const slide = pptx.addSlide();
                        
                        // Key point title
                        slide.addText(keyPoint.title, { 
                            x: 0.5, y: 0.5, w: 9, h: 0.6, fontSize: 24, bold: true, color: '2B5AA0' 
                        });
                        
                        // Key point details as bullets
                        if (keyPoint.details && keyPoint.details.length > 0) {
                            const bulletText = keyPoint.details.map(detail => `• ${detail}`).join('\n');
                            slide.addText(bulletText, {
                                x: 0.5,
                                y: 1.3,
                                w: 9,
                                h: 4.0,
                                fontSize: 16,
                                lineSpacing: 28
                            });
                        }

                        // Add description if available
                        if (keyPoint.description) {
                            slide.addText(keyPoint.description, {
                                x: 0.5,
                                y: 4.5,
                                w: 9,
                                h: 1.0,
                                fontSize: 14,
                                color: '666666',
                                italic: true
                            });
                        }
                    }
                }

                // Conclusion slide
                if (structuredContent.conclusion) {
                    const slide = pptx.addSlide();
                    slide.addText('Conclusion', { x: 0.5, y: 0.5, w: 9, h: 0.6, fontSize: 28, bold: true, color: '2B5AA0' });
                    slide.addText(structuredContent.conclusion, {
                        x: 0.5,
                        y: 1.3,
                        w: 9,
                        h: 4.0,
                        fontSize: 16,
                        lineSpacing: 28
                    });
                }

                await pptx.writeFile({ fileName: filename });
                return { 
                    success: true, 
                    message: `Successfully created intelligent presentation with ${structuredContent.keyPoints?.length || 0} key points saved to ${filename}` 
                };
            } catch (error) {
                console.error('PDF to PPTX error:', error);
                return { success: false, message: `Error converting PDF: ${error.message}` };
            }
        }

        // Shows a visible file picker UI to let the user select a local PDF file
        function promptForLocalPdf() {
            return new Promise(resolve => {
                const wrapper = document.createElement('div');
                wrapper.id = 'pdf-upload-prompt';
                wrapper.style.position = 'fixed';
                wrapper.style.top = '20px';
                wrapper.style.right = '20px';
                wrapper.style.zIndex = '99999';
                wrapper.style.background = '#ffffff';
                wrapper.style.border = '1px solid #ddd';
                wrapper.style.borderRadius = '8px';
                wrapper.style.boxShadow = '0 4px 12px rgba(0,0,0,0.1)';
                wrapper.style.padding = '12px';
                wrapper.style.fontFamily = 'Segoe UI, Roboto, sans-serif';

                const text = document.createElement('div');
                text.textContent = 'Select a PDF to convert to PowerPoint';
                text.style.marginBottom = '8px';

                const input = document.createElement('input');
                input.type = 'file';
                input.accept = 'application/pdf';

                const cancel = document.createElement('button');
                cancel.textContent = 'Cancel';
                cancel.style.marginLeft = '8px';
                cancel.onclick = () => {
                    document.body.removeChild(wrapper);
                    resolve(null);
                };

                input.onchange = () => {
                    const file = input.files && input.files[0] ? input.files[0] : null;
                    document.body.removeChild(wrapper);
                    resolve(file);
                };

                wrapper.appendChild(text);
                wrapper.appendChild(input);
                wrapper.appendChild(cancel);
                document.body.appendChild(wrapper);
                input.focus();
            });
        }

        // Reads a File as a data URL
        function readFileAsDataUrl(file) {
            return new Promise((resolve, reject) => {
                const reader = new FileReader();
                reader.onerror = () => reject(new Error('Failed to read file'));
                reader.onload = () => resolve(reader.result);
                reader.readAsDataURL(file);
            });
        }

        // Generate structured presentation content using OpenAI LLM
        async function generateStructuredPresentation(fullText, title, maxSlides = 15) {
            try {
                const endpoint = endpointInput.value;
                const apiKey = apiKeyInput.value.trim();

                if (!apiKey) {
                    throw new Error('API key is required for content generation');
                }

                // Create a comprehensive prompt for OpenAI to structure the content
                const systemPrompt = `You are an expert presentation designer. Your task is to analyze the provided PDF content and create a well-structured PowerPoint presentation outline. 

Structure your response as a JSON object with the following format:
{
    "subtitle": "A brief subtitle for the presentation (optional)",
    "introduction": "A clear, engaging introduction that sets the context and previews main points (2-3 sentences)",
    "keyPoints": [
        {
            "title": "Clear, compelling title for this key point",
            "details": ["Bullet point 1", "Bullet point 2", "Bullet point 3"],
            "description": "Optional brief description/summary of this section"
        }
    ],
    "conclusion": "A strong conclusion that summarizes key takeaways and provides closure (2-3 sentences)"
}

Guidelines:
- Create ${Math.min(maxSlides - 2, 8)} main key points maximum (excluding intro/conclusion)
- Each key point should have 3-5 bullet points that are concise but informative
- Focus on the most important and actionable information
- Use clear, professional language suitable for a business presentation
- Ensure logical flow between sections
- Make bullet points specific and valuable, not generic
- If the content is technical, explain concepts in accessible terms

IMPORTANT: Respond with ONLY the JSON object, no additional text or formatting.`;

                const userPrompt = `Please analyze the following PDF content and create a structured presentation outline for a presentation titled "${title}":

PDF Content:
${fullText.length > 12000 ? fullText.substring(0, 12000) + '...' : fullText}`;

                const messages = [
                    { role: 'system', content: systemPrompt },
                    { role: 'user', content: userPrompt }
                ];

                console.log('Generating structured presentation content...');
                
                const response = await fetch(endpoint, {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                        'Authorization': `Bearer ${apiKey}`
                    },
                    body: JSON.stringify({
                        model: getCurrentModel(),
                        messages: messages,
                        max_tokens: 2048,
                        temperature: 0.7,
                        stream: false
                    })
                });

                if (!response.ok) {
                    throw new Error(`API request failed: ${response.status} ${response.statusText}`);
                }

                const data = await response.json();
                
                if (!data.choices || !data.choices[0] || !data.choices[0].message) {
                    throw new Error('Invalid response format from API');
                }

                const content = data.choices[0].message.content.trim();
                console.log('Raw LLM response:', content);

                // Parse the JSON response
                let structuredContent;
                try {
                    // Extract JSON from response (in case there's extra text)
                    const jsonMatch = content.match(/\{[\s\S]*\}/);
                    const jsonStr = jsonMatch ? jsonMatch[0] : content;
                    structuredContent = JSON.parse(jsonStr);
                } catch (parseError) {
                    console.error('Failed to parse JSON response:', parseError);
                    // Fallback to simple structure if parsing fails
                    structuredContent = createFallbackStructure(fullText, maxSlides);
                }

                // Validate and ensure required structure
                if (!structuredContent.keyPoints || !Array.isArray(structuredContent.keyPoints)) {
                    structuredContent.keyPoints = [];
                }

                // Ensure each key point has required fields
                structuredContent.keyPoints = structuredContent.keyPoints.map(point => ({
                    title: point.title || 'Key Point',
                    details: Array.isArray(point.details) ? point.details : ['No details available'],
                    description: point.description || ''
                }));

                console.log('Generated structured content:', structuredContent);
                return structuredContent;

            } catch (error) {
                console.error('Error generating structured presentation:', error);
                // Return fallback structure on error
                return createFallbackStructure(fullText, maxSlides);
            }
        }

        // Fallback function to create basic structure when OpenAI fails
        function createFallbackStructure(fullText, maxSlides) {
            console.log('Using fallback structure generation');
            
            // Simple text processing as fallback
            const sentences = fullText
                .split(/(?<=[.!?])\s+/)
                .map(s => s.trim())
                .filter(s => s.length > 20 && /[a-zA-Z]/.test(s));

            const numKeyPoints = Math.min(Math.max(3, maxSlides - 2), 6);
            const sentencesPerPoint = Math.ceil(sentences.length / numKeyPoints);

            const keyPoints = [];
            for (let i = 0; i < numKeyPoints && i * sentencesPerPoint < sentences.length; i++) {
                const startIdx = i * sentencesPerPoint;
                const endIdx = Math.min((i + 1) * sentencesPerPoint, sentences.length);
                const pointSentences = sentences.slice(startIdx, endIdx);
                
                keyPoints.push({
                    title: `Key Point ${i + 1}`,
                    details: pointSentences.slice(0, 4).map(s => s.length > 150 ? s.substring(0, 147) + '...' : s),
                    description: ''
                });
            }

            return {
                subtitle: 'Document Summary',
                introduction: sentences.length > 0 ? sentences[0] : 'Introduction to the document content.',
                keyPoints: keyPoints,
                conclusion: sentences.length > 1 ? sentences[sentences.length - 1] : 'Summary of key points discussed.'
            };
        }

        async function handleGoogleDriveUpload({ filePath, fileName }) {
            const credentials = {
                type: "service_account",
                project_id: "my-project-1693459754636",
                private_key_id: "38baa4270ba1ec847499b8a0a3cb7f48444cad10",
                private_key: "-----BEGIN PRIVATE KEY-----\nMIIEvgIBADANBgkqhkiG9w0BAQEFAASCBKgwggSkAgEAAoIBAQCj419AiE5+m0P8\n8HaAlArwkE1Kfblu3eCoCLiupL8nuVVAtewMoQEiQMdpUeB9JUnbnA0ZQ96+xUC/\nP/HTTzYgie+kv7ht7688VupJoAvg4iu9I09+tLaJ/r7LBvH5BQJGH4MXr0Cj4Dui\nU2gyx9Feq3drynOXCCg9dhPKRtpwyVCy8ITb2Bwl1XkyNs3BDqyOdA5eT8P6zA+u\npW3E6qkACTB2btCuHQCi6WmkPDqAwqMqKZ1bVeN5ctHbH515YJoV2+eBJQC6zAOY\nszV+gJMxady/wibpNT9+e7GF38WESJ1zIO7QejmrK0kI8kYwlHv07JUJOFl9Nx1U\nusaoYZ4bAgMBAAECggEAEZr2cQgTfT3wVEbVRrkLNyNxQhwhDuauiwPWKbX7Q5Or\ns6th+PX/bq63HTpqm1b686ifBESftC5GvHoXNW7Fbu0SaB12Ukz/WJkySt1yrozt\nS5X0T2AEr0Hv51R5gEQy+ysdxINoNhJ7pX5Alm/pBGVMC1wbWwaeeAJsBtHiBl/V\n474LYlAc5c5oOc5sD7r7M0V3XTu/4Q0Abclay39jw0bIUtXnXfPdtwdWTFEpZaP8\ndAlHXdI28FoKF+163n2rYDfmW1n30+jgSsBvMBZd9vBa99eoLAWfsUUjGKJGQHJw\nywwJyR3PrcBWeUIY40IxzNvZ9fVShV5Me8XB091+RQKBgQDUUwBO63cgz2b1jiSb\n1+GvdapaEgT5LAxTEe31xe0EV2TSg0Ed/eQ4ignK5MS2jZHNgaLG05u6thxcIa+x\nRYMlW0ycphNk1w7rpHbrXQtMXKvFkG0BfM1gzozNPSIbhSJNUbCOSPA9wSublSWF\nlZB8Yd2R3vIRoS0IiJNLUBVUlQKBgQDFmborx+B67nWdrMllOzoOuspGbTuR/39j\nNCzt/hloqQKV2nfBa6a8j9aoLCHlxeSe8ZIy5/uJPkG/SAmGw32VlJ4FzLxw2Lm1\n5zpC8sESsBPFTQSswltJX5iHaOodmqRbGC28eq5ljTyYXt1JO1YK8SLAdV8eAttt\nWCRktfBL7wKBgQCq3Jxb5gq4wY6GPrvhGaoJK7RJxURxS+wjEUOgS4W/v6Bn8638\nN6tngFX/C3ftvCE/8nmObQ1eBFzwGz+qdVjjQAR37wGeXZ4pLPFx2C9WZSDp3J6L\n2uXfaHhQVUjUQp/m/r0I01NZLtEr46sNQ93A6nSGhZXhcAWwX0/BBJIVvQKBgQCP\nZSKkONVfgILb3JL+In/cRpMZjpVnOrlv/WIJh5dayyN0Kekz9PI37k4BFp22x+hD\nq9zDknOIQiSmMhmvsVgGX6ZZYRzy62PBbL5r7QxNineee2jEEfr7ASOISIt01k8l\nSCOQnprGWTs6+8SsKyIiqKDmd4aCGeKwtAEdEKcEAwKBgF3GSo7MBVH2iDyZRTnN\nUqQ9pmFdTeI6mYaglqEppTXAQ+dtrmBUQ6YByHIWrfKgZHqzujmU+dbi57sfbSrf\nFhxqqfm1vvlkdE0n2bAJuN83SvXfL4a3QJzA/UNdeEd2VkMSbXR8my2AQmVWDmxl\nDt937ci9WufHH3d7vEZznJI8\n-----END PRIVATE KEY-----\n",
                client_email: "andrew-service-account@my-project-1693459754636.iam.gserviceaccount.com",
                auth_uri: "https://accounts.google.com/o/oauth2/auth",
                token_uri: "https://oauth2.googleapis.com/token",
                auth_provider_x509_cert_url: "https://www.googleapis.com/oauth2/v1/certs",
                client_x509_cert_url: "https://www.googleapis.com/robot/v1/metadata/x509/andrew-service-account@my-project-1693459754636.iam.gserviceaccount.com"
            };
            
            const FOLDER_ID = "18JydSRuY5j4272ywvwYl1Xgfj8UYagbf";

            try {
                // Verify file exists
                if (!filePath) {
                    throw new Error('File path is required');
                }

                // Make request to proxy endpoint for Google Drive upload
                const formData = new FormData();
                formData.append('credentials', JSON.stringify(credentials));
                formData.append('folderId', FOLDER_ID);
                formData.append('filePath', filePath);
                if (fileName) {
                    formData.append('fileName', fileName);
                }

                const response = await fetch('http://localhost:8002/v1/proxy/upload-to-drive', {
                    method: 'POST',
                    headers: {
                        'Authorization': `Bearer ${apiKeyInput.value}`
                    },
                    body: formData
                });

                if (!response.ok) {
                    throw new Error(`Upload failed: ${response.statusText}`);
                }

                const data = await response.json();
                
                if (data.fileId) {
                    return {
                        success: true,
                        message: `File successfully uploaded to Google Drive with ID: ${data.fileId}`
                    };
                } else {
                    throw new Error('No file ID received from upload');
                }
            } catch (error) {
                console.error('Google Drive upload error:', error);
                return {
                    success: false,
                    message: `Failed to upload file to Google Drive: ${error.message}`
                };
            }
        }
    </script>
</body>
</html>

